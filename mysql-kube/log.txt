* 
* ==> Audit <==
* |--------------|------------------------------------------|----------|----------|---------|---------------------|---------------------|
|   Command    |                   Args                   | Profile  |   User   | Version |     Start Time      |      End Time       |
|--------------|------------------------------------------|----------|----------|---------|---------------------|---------------------|
| start        |                                          | minikube | yaswitha | v1.32.0 | 04 Feb 24 14:53 +08 | 04 Feb 24 14:56 +08 |
| start        | --vm-driver=docker                       | minikube | yaswitha | v1.32.0 | 04 Feb 24 15:01 +08 | 04 Feb 24 15:02 +08 |
| stop         |                                          | minikube | yaswitha | v1.32.0 | 05 Feb 24 09:43 +08 | 05 Feb 24 09:43 +08 |
| start        |                                          | minikube | yaswitha | v1.32.0 | 05 Feb 24 09:43 +08 | 05 Feb 24 09:44 +08 |
| service      | mongo-express-service                    | minikube | yaswitha | v1.32.0 | 05 Feb 24 10:30 +08 | 05 Feb 24 10:35 +08 |
| service      | mongo-express-service                    | minikube | yaswitha | v1.32.0 | 05 Feb 24 10:35 +08 | 05 Feb 24 10:50 +08 |
| service      | mongo-express-service                    | minikube | yaswitha | v1.32.0 | 05 Feb 24 10:51 +08 | 05 Feb 24 10:56 +08 |
| service      | mongo-express-service                    | minikube | yaswitha | v1.32.0 | 05 Feb 24 10:57 +08 | 05 Feb 24 11:02 +08 |
| delete       |                                          | minikube | yaswitha | v1.32.0 | 05 Feb 24 11:07 +08 | 05 Feb 24 11:07 +08 |
| start        | --memory=4096                            | minikube | yaswitha | v1.32.0 | 05 Feb 24 11:08 +08 | 05 Feb 24 11:11 +08 |
|              | --driver=virtualbox                      |          |          |         |                     |                     |
| service      | mongo-express-service                    | minikube | yaswitha | v1.32.0 | 05 Feb 24 11:16 +08 | 05 Feb 24 11:16 +08 |
| stop         |                                          | minikube | yaswitha | v1.32.0 | 05 Feb 24 18:46 +08 | 05 Feb 24 18:47 +08 |
| start        |                                          | minikube | yaswitha | v1.32.0 | 05 Feb 24 18:47 +08 | 05 Feb 24 18:50 +08 |
| service      | mongo-express-service                    | minikube | yaswitha | v1.32.0 | 05 Feb 24 19:03 +08 | 05 Feb 24 19:03 +08 |
| service      | mongo-express-service                    | minikube | yaswitha | v1.32.0 | 05 Feb 24 21:10 +08 | 05 Feb 24 21:10 +08 |
| start        |                                          | minikube | yaswitha | v1.32.0 | 06 Feb 24 09:19 +08 | 06 Feb 24 09:21 +08 |
| addons       | enable ingress                           | minikube | yaswitha | v1.32.0 | 06 Feb 24 10:09 +08 | 06 Feb 24 10:10 +08 |
| dashboard    |                                          | minikube | yaswitha | v1.32.0 | 06 Feb 24 10:23 +08 |                     |
| delete       | mysql                                    | minikube | yaswitha | v1.32.0 | 06 Feb 24 16:52 +08 |                     |
| stop         |                                          | minikube | yaswitha | v1.32.0 | 06 Feb 24 21:08 +08 | 06 Feb 24 21:08 +08 |
| start        |                                          | minikube | yaswitha | v1.32.0 | 07 Feb 24 11:30 +08 |                     |
| start        |                                          | minikube | yaswitha | v1.32.0 | 07 Feb 24 11:42 +08 |                     |
| stop         |                                          | minikube | yaswitha | v1.32.0 | 07 Feb 24 11:52 +08 | 07 Feb 24 11:52 +08 |
| start        |                                          | minikube | yaswitha | v1.32.0 | 07 Feb 24 11:52 +08 |                     |
| start        |                                          | minikube | yaswitha | v1.32.0 | 07 Feb 24 11:57 +08 |                     |
| start        |                                          | minikube | yaswitha | v1.32.0 | 07 Feb 24 12:07 +08 |                     |
| start        | systemctl enable                         | minikube | yaswitha | v1.32.0 | 07 Feb 24 12:42 +08 |                     |
|              | kubelet.service                          |          |          |         |                     |                     |
| start        | --kubernetes-version v1.29.1             | minikube | yaswitha | v1.32.0 | 07 Feb 24 12:43 +08 |                     |
| delete       |                                          | minikube | yaswitha | v1.32.0 | 07 Feb 24 12:59 +08 | 07 Feb 24 12:59 +08 |
| start        |                                          | minikube | yaswitha | v1.32.0 | 07 Feb 24 12:59 +08 | 07 Feb 24 13:00 +08 |
| ssh          |                                          | minikube | yaswitha | v1.32.0 | 07 Feb 24 17:13 +08 | 07 Feb 24 17:31 +08 |
| ip           | mysql                                    | minikube | yaswitha | v1.32.0 | 07 Feb 24 17:21 +08 | 07 Feb 24 17:21 +08 |
| ssh          |                                          | minikube | yaswitha | v1.32.0 | 07 Feb 24 17:32 +08 |                     |
| start        |                                          | minikube | yaswitha | v1.32.0 | 08 Feb 24 08:52 +08 | 08 Feb 24 08:53 +08 |
| stop         |                                          | minikube | yaswitha | v1.32.0 | 09 Feb 24 22:43 +08 | 09 Feb 24 22:53 +08 |
| start        |                                          | minikube | yaswitha | v1.32.0 | 09 Feb 24 23:04 +08 | 09 Feb 24 23:05 +08 |
| stop         |                                          | minikube | yaswitha | v1.32.0 | 10 Feb 24 08:34 +08 |                     |
| stop         |                                          | minikube | yaswitha | v1.32.0 | 10 Feb 24 08:42 +08 |                     |
| stop         |                                          | minikube | yaswitha | v1.32.0 | 10 Feb 24 08:46 +08 |                     |
| delete       |                                          | minikube | yaswitha | v1.32.0 | 10 Feb 24 08:48 +08 |                     |
| start        |                                          | minikube | yaswitha | v1.32.0 | 10 Feb 24 09:04 +08 | 10 Feb 24 09:05 +08 |
| stop         |                                          | minikube | yaswitha | v1.32.0 | 10 Feb 24 18:16 +08 |                     |
| update-check |                                          | minikube | yaswitha | v1.32.0 | 12 Feb 24 09:46 +08 | 12 Feb 24 09:46 +08 |
| update-check |                                          | minikube | yaswitha | v1.32.0 | 12 Feb 24 09:49 +08 | 12 Feb 24 09:49 +08 |
| start        | -- memory=16384 -- cpus=4                | minikube | yaswitha | v1.32.0 | 12 Feb 24 10:14 +08 | 12 Feb 24 10:16 +08 |
| service      | stable-kube-prometheus-sta-prometheus-np | minikube | yaswitha | v1.32.0 | 12 Feb 24 10:44 +08 |                     |
|              | -n monitoring                            |          |          |         |                     |                     |
| service      | list                                     | minikube | yaswitha | v1.32.0 | 12 Feb 24 10:44 +08 | 12 Feb 24 10:44 +08 |
| service      | mysql -n monitoring                      | minikube | yaswitha | v1.32.0 | 12 Feb 24 10:49 +08 |                     |
| service      | list                                     | minikube | yaswitha | v1.32.0 | 12 Feb 24 10:50 +08 | 12 Feb 24 10:50 +08 |
| service      | stable-kube-prometheus-sta-prometheus-np | minikube | yaswitha | v1.32.0 | 12 Feb 24 10:54 +08 |                     |
|              | -n monitoring                            |          |          |         |                     |                     |
| service      | stable-kube-prometheus-sta-prometheus-np | minikube | yaswitha | v1.32.0 | 12 Feb 24 10:55 +08 |                     |
|              | -n monitoring                            |          |          |         |                     |                     |
| service      | stable-kube-prometheus-sta-prometheus-np | minikube | yaswitha | v1.32.0 | 12 Feb 24 10:57 +08 |                     |
|              | -n monitoring                            |          |          |         |                     |                     |
| service      | stable-kube-prometheus-sta-prometheus-np | minikube | yaswitha | v1.32.0 | 12 Feb 24 10:58 +08 |                     |
|              | -n monitoring                            |          |          |         |                     |                     |
|--------------|------------------------------------------|----------|----------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2024/02/12 10:14:44
Running on machine: Yaswithas-MacBook-Air
Binary: Built with gc go1.21.3 for darwin/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0212 10:14:44.067579   66178 out.go:296] Setting OutFile to fd 1 ...
I0212 10:14:44.070143   66178 out.go:348] isatty.IsTerminal(1) = true
I0212 10:14:44.070155   66178 out.go:309] Setting ErrFile to fd 2...
I0212 10:14:44.070168   66178 out.go:348] isatty.IsTerminal(2) = true
I0212 10:14:44.074971   66178 root.go:338] Updating PATH: /Users/yaswitha/.minikube/bin
I0212 10:14:44.149484   66178 out.go:303] Setting JSON to false
I0212 10:14:44.215347   66178 start.go:128] hostinfo: {"hostname":"Yaswithas-MacBook-Air.local","uptime":351041,"bootTime":1707353043,"procs":522,"os":"darwin","platform":"darwin","platformFamily":"Standalone Workstation","platformVersion":"12.7.3","kernelVersion":"21.6.0","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"e71a6db4-2cc6-5b2a-a817-722231a3ef9f"}
W0212 10:14:44.216173   66178 start.go:136] gopshost.Virtualization returned error: not implemented yet
I0212 10:14:44.234363   66178 out.go:177] 😄  minikube v1.32.0 on Darwin 12.7.3
I0212 10:14:44.258689   66178 notify.go:220] Checking for updates...
I0212 10:14:44.259770   66178 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0212 10:14:44.261056   66178 driver.go:378] Setting default libvirt URI to qemu:///system
I0212 10:14:44.437895   66178 docker.go:122] docker version: linux-25.0.2:Docker Desktop 4.27.1 (136059)
I0212 10:14:44.440188   66178 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0212 10:14:45.764408   66178 cli_runner.go:217] Completed: docker system info --format "{{json .}}": (1.324089614s)
I0212 10:14:45.765568   66178 info.go:266] docker info: {ID:37d26dc4-26fd-412c-af9e-e3b0d9894ebb Containers:38 ContainersRunning:20 ContainersPaused:0 ContainersStopped:18 Images:15 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:168 OomKillDisable:false NGoroutines:175 SystemTime:2024-02-12 02:14:45.731127947 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:12 KernelVersion:6.6.12-linuxkit OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:4107567104 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:25.0.2 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:ae07eda36dd25f8a1b98dfbf587313b99c0190bb Expected:ae07eda36dd25f8a1b98dfbf587313b99c0190bb} RuncCommit:{ID:v1.1.12-0-g51d5e94 Expected:v1.1.12-0-g51d5e94} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined name=cgroupns] ProductLicense: Warnings:[WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/Users/yaswitha/.docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.12.1-desktop.4] map[Name:compose Path:/Users/yaswitha/.docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.24.3-desktop.1] map[Name:debug Path:/Users/yaswitha/.docker/cli-plugins/docker-debug SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container. Vendor:Docker Inc. Version:0.0.22] map[Name:dev Path:/Users/yaswitha/.docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:/Users/yaswitha/.docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.21] map[Name:feedback Path:/Users/yaswitha/.docker/cli-plugins/docker-feedback SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.4] map[Name:init Path:/Users/yaswitha/.docker/cli-plugins/docker-init SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.0.0] map[Name:sbom Path:/Users/yaswitha/.docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:/Users/yaswitha/.docker/cli-plugins/docker-scout SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.3.0]] Warnings:<nil>}}
I0212 10:14:45.779784   66178 out.go:177] ✨  Using the docker driver based on existing profile
I0212 10:14:45.811106   66178 start.go:298] selected driver: docker
I0212 10:14:45.811302   66178 start.go:902] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0212 10:14:45.811559   66178 start.go:913] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0212 10:14:45.811828   66178 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0212 10:14:46.143968   66178 info.go:266] docker info: {ID:37d26dc4-26fd-412c-af9e-e3b0d9894ebb Containers:38 ContainersRunning:20 ContainersPaused:0 ContainersStopped:18 Images:15 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:168 OomKillDisable:false NGoroutines:175 SystemTime:2024-02-12 02:14:46.109200361 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:12 KernelVersion:6.6.12-linuxkit OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:4107567104 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:25.0.2 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:ae07eda36dd25f8a1b98dfbf587313b99c0190bb Expected:ae07eda36dd25f8a1b98dfbf587313b99c0190bb} RuncCommit:{ID:v1.1.12-0-g51d5e94 Expected:v1.1.12-0-g51d5e94} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=unconfined name=cgroupns] ProductLicense: Warnings:[WARNING: daemon is not using the default seccomp profile] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/Users/yaswitha/.docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.12.1-desktop.4] map[Name:compose Path:/Users/yaswitha/.docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.24.3-desktop.1] map[Name:debug Path:/Users/yaswitha/.docker/cli-plugins/docker-debug SchemaVersion:0.1.0 ShortDescription:Get a shell into any image or container. Vendor:Docker Inc. Version:0.0.22] map[Name:dev Path:/Users/yaswitha/.docker/cli-plugins/docker-dev SchemaVersion:0.1.0 ShortDescription:Docker Dev Environments Vendor:Docker Inc. Version:v0.1.0] map[Name:extension Path:/Users/yaswitha/.docker/cli-plugins/docker-extension SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.21] map[Name:feedback Path:/Users/yaswitha/.docker/cli-plugins/docker-feedback SchemaVersion:0.1.0 ShortDescription:Provide feedback, right in your terminal! Vendor:Docker Inc. Version:v1.0.4] map[Name:init Path:/Users/yaswitha/.docker/cli-plugins/docker-init SchemaVersion:0.1.0 ShortDescription:Creates Docker-related starter files for your project Vendor:Docker Inc. Version:v1.0.0] map[Name:sbom Path:/Users/yaswitha/.docker/cli-plugins/docker-sbom SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scout Path:/Users/yaswitha/.docker/cli-plugins/docker-scout SchemaVersion:0.1.0 ShortDescription:Docker Scout Vendor:Docker Inc. Version:v1.3.0]] Warnings:<nil>}}
I0212 10:14:46.428983   66178 cni.go:84] Creating CNI manager for ""
I0212 10:14:46.429526   66178 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0212 10:14:46.429554   66178 start_flags.go:323] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0212 10:14:46.447559   66178 out.go:177] 👍  Starting control plane node minikube in cluster minikube
I0212 10:14:46.463699   66178 cache.go:121] Beginning downloading kic base image for docker with docker
I0212 10:14:46.479805   66178 out.go:177] 🚜  Pulling base image ...
I0212 10:14:46.506968   66178 preload.go:132] Checking if preload exists for k8s version v1.28.3 and runtime docker
I0212 10:14:46.507318   66178 preload.go:148] Found local preload: /Users/yaswitha/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.28.3-docker-overlay2-amd64.tar.lz4
I0212 10:14:46.507354   66178 cache.go:56] Caching tarball of preloaded images
I0212 10:14:46.507403   66178 image.go:79] Checking for gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 in local docker daemon
I0212 10:14:46.510518   66178 preload.go:174] Found /Users/yaswitha/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.28.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0212 10:14:46.510796   66178 cache.go:59] Finished verifying existence of preloaded tar for  v1.28.3 on docker
I0212 10:14:46.511128   66178 profile.go:148] Saving config to /Users/yaswitha/.minikube/profiles/minikube/config.json ...
I0212 10:14:46.625552   66178 image.go:83] Found gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 in local docker daemon, skipping pull
I0212 10:14:46.625570   66178 cache.go:144] gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 exists in daemon, skipping load
I0212 10:14:46.625624   66178 cache.go:194] Successfully downloaded all kic artifacts
I0212 10:14:46.627880   66178 start.go:365] acquiring machines lock for minikube: {Name:mkcfac1f4721ab1ae534a279ccb9935bd4f0e8cd Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0212 10:14:46.628832   66178 start.go:369] acquired machines lock for "minikube" in 822.085µs
I0212 10:14:46.628876   66178 start.go:96] Skipping create...Using existing machine configuration
I0212 10:14:46.628899   66178 fix.go:54] fixHost starting: 
I0212 10:14:46.629442   66178 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0212 10:14:46.732100   66178 fix.go:102] recreateIfNeeded on minikube: state=Stopped err=<nil>
W0212 10:14:46.732518   66178 fix.go:128] unexpected machine state, will restart: <nil>
I0212 10:14:46.743163   66178 out.go:177] 🔄  Restarting existing docker container for "minikube" ...
I0212 10:14:46.758237   66178 cli_runner.go:164] Run: docker start minikube
I0212 10:14:47.388335   66178 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0212 10:14:47.613700   66178 kic.go:430] container "minikube" state is running.
I0212 10:14:47.617864   66178 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0212 10:14:47.814121   66178 profile.go:148] Saving config to /Users/yaswitha/.minikube/profiles/minikube/config.json ...
I0212 10:14:47.821570   66178 machine.go:88] provisioning docker machine ...
I0212 10:14:47.821681   66178 ubuntu.go:169] provisioning hostname "minikube"
I0212 10:14:47.822220   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0212 10:14:48.035238   66178 main.go:141] libmachine: Using SSH client type: native
I0212 10:14:48.151928   66178 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x1405ca0] 0x1408980 <nil>  [] 0s} 127.0.0.1 60875 <nil> <nil>}
I0212 10:14:48.151968   66178 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0212 10:14:48.161565   66178 main.go:141] libmachine: Error dialing TCP: ssh: handshake failed: EOF
I0212 10:14:51.581266   66178 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0212 10:14:51.587551   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0212 10:14:51.748365   66178 main.go:141] libmachine: Using SSH client type: native
I0212 10:14:51.749461   66178 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x1405ca0] 0x1408980 <nil>  [] 0s} 127.0.0.1 60875 <nil> <nil>}
I0212 10:14:51.749508   66178 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0212 10:14:52.118411   66178 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0212 10:14:52.119580   66178 ubuntu.go:175] set auth options {CertDir:/Users/yaswitha/.minikube CaCertPath:/Users/yaswitha/.minikube/certs/ca.pem CaPrivateKeyPath:/Users/yaswitha/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/Users/yaswitha/.minikube/machines/server.pem ServerKeyPath:/Users/yaswitha/.minikube/machines/server-key.pem ClientKeyPath:/Users/yaswitha/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/Users/yaswitha/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/Users/yaswitha/.minikube}
I0212 10:14:52.119627   66178 ubuntu.go:177] setting up certificates
I0212 10:14:52.120319   66178 provision.go:83] configureAuth start
I0212 10:14:52.120508   66178 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0212 10:14:52.338015   66178 provision.go:138] copyHostCerts
I0212 10:14:52.344446   66178 exec_runner.go:144] found /Users/yaswitha/.minikube/key.pem, removing ...
I0212 10:14:52.344968   66178 exec_runner.go:203] rm: /Users/yaswitha/.minikube/key.pem
I0212 10:14:52.345530   66178 exec_runner.go:151] cp: /Users/yaswitha/.minikube/certs/key.pem --> /Users/yaswitha/.minikube/key.pem (1675 bytes)
I0212 10:14:52.421434   66178 exec_runner.go:144] found /Users/yaswitha/.minikube/ca.pem, removing ...
I0212 10:14:52.421451   66178 exec_runner.go:203] rm: /Users/yaswitha/.minikube/ca.pem
I0212 10:14:52.422104   66178 exec_runner.go:151] cp: /Users/yaswitha/.minikube/certs/ca.pem --> /Users/yaswitha/.minikube/ca.pem (1082 bytes)
I0212 10:14:52.463111   66178 exec_runner.go:144] found /Users/yaswitha/.minikube/cert.pem, removing ...
I0212 10:14:52.463127   66178 exec_runner.go:203] rm: /Users/yaswitha/.minikube/cert.pem
I0212 10:14:52.463401   66178 exec_runner.go:151] cp: /Users/yaswitha/.minikube/certs/cert.pem --> /Users/yaswitha/.minikube/cert.pem (1127 bytes)
I0212 10:14:52.463824   66178 provision.go:112] generating server cert: /Users/yaswitha/.minikube/machines/server.pem ca-key=/Users/yaswitha/.minikube/certs/ca.pem private-key=/Users/yaswitha/.minikube/certs/ca-key.pem org=yaswitha.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0212 10:14:52.668608   66178 provision.go:172] copyRemoteCerts
I0212 10:14:52.669200   66178 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0212 10:14:52.669339   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0212 10:14:52.928067   66178 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60875 SSHKeyPath:/Users/yaswitha/.minikube/machines/minikube/id_rsa Username:docker}
I0212 10:14:53.163168   66178 ssh_runner.go:362] scp /Users/yaswitha/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1082 bytes)
I0212 10:14:53.289611   66178 ssh_runner.go:362] scp /Users/yaswitha/.minikube/machines/server.pem --> /etc/docker/server.pem (1208 bytes)
I0212 10:14:53.508038   66178 ssh_runner.go:362] scp /Users/yaswitha/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0212 10:14:53.935039   66178 provision.go:86] duration metric: configureAuth took 1.813754327s
I0212 10:14:53.935064   66178 ubuntu.go:193] setting minikube options for container-runtime
I0212 10:14:53.939137   66178 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0212 10:14:53.939283   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0212 10:14:54.298162   66178 main.go:141] libmachine: Using SSH client type: native
I0212 10:14:54.300217   66178 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x1405ca0] 0x1408980 <nil>  [] 0s} 127.0.0.1 60875 <nil> <nil>}
I0212 10:14:54.300238   66178 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0212 10:14:54.731290   66178 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0212 10:14:54.731308   66178 ubuntu.go:71] root file system type: overlay
I0212 10:14:54.732655   66178 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0212 10:14:54.732858   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0212 10:14:55.005600   66178 main.go:141] libmachine: Using SSH client type: native
I0212 10:14:55.006687   66178 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x1405ca0] 0x1408980 <nil>  [] 0s} 127.0.0.1 60875 <nil> <nil>}
I0212 10:14:55.006886   66178 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0212 10:14:55.276590   66178 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0212 10:14:55.278077   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0212 10:14:55.421164   66178 main.go:141] libmachine: Using SSH client type: native
I0212 10:14:55.422256   66178 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x1405ca0] 0x1408980 <nil>  [] 0s} 127.0.0.1 60875 <nil> <nil>}
I0212 10:14:55.422313   66178 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0212 10:14:55.644948   66178 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0212 10:14:55.644976   66178 machine.go:91] provisioned docker machine in 7.823156928s
I0212 10:14:55.645035   66178 start.go:300] post-start starting for "minikube" (driver="docker")
I0212 10:14:55.646131   66178 start.go:329] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0212 10:14:55.646846   66178 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0212 10:14:55.646945   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0212 10:14:55.863303   66178 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60875 SSHKeyPath:/Users/yaswitha/.minikube/machines/minikube/id_rsa Username:docker}
I0212 10:14:56.012235   66178 ssh_runner.go:195] Run: cat /etc/os-release
I0212 10:14:56.027327   66178 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0212 10:14:56.027363   66178 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0212 10:14:56.027378   66178 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0212 10:14:56.027384   66178 info.go:137] Remote host: Ubuntu 22.04.3 LTS
I0212 10:14:56.027898   66178 filesync.go:126] Scanning /Users/yaswitha/.minikube/addons for local assets ...
I0212 10:14:56.028640   66178 filesync.go:126] Scanning /Users/yaswitha/.minikube/files for local assets ...
I0212 10:14:56.028889   66178 start.go:303] post-start completed in 383.829846ms
I0212 10:14:56.031944   66178 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0212 10:14:56.032080   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0212 10:14:56.155706   66178 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60875 SSHKeyPath:/Users/yaswitha/.minikube/machines/minikube/id_rsa Username:docker}
I0212 10:14:56.275859   66178 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0212 10:14:56.292317   66178 fix.go:56] fixHost completed within 9.663126095s
I0212 10:14:56.292347   66178 start.go:83] releasing machines lock for "minikube", held for 9.663208442s
I0212 10:14:56.292540   66178 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0212 10:14:56.413437   66178 ssh_runner.go:195] Run: cat /version.json
I0212 10:14:56.413665   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0212 10:14:56.416195   66178 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0212 10:14:56.417171   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0212 10:14:56.536092   66178 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60875 SSHKeyPath:/Users/yaswitha/.minikube/machines/minikube/id_rsa Username:docker}
I0212 10:14:56.545957   66178 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60875 SSHKeyPath:/Users/yaswitha/.minikube/machines/minikube/id_rsa Username:docker}
I0212 10:14:56.655928   66178 ssh_runner.go:195] Run: systemctl --version
I0212 10:14:57.053154   66178 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0212 10:14:57.066302   66178 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
I0212 10:14:57.151712   66178 cni.go:230] loopback cni configuration patched: "/etc/cni/net.d/*loopback.conf*" found
I0212 10:14:57.151925   66178 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0212 10:14:57.190424   66178 cni.go:259] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I0212 10:14:57.190446   66178 start.go:472] detecting cgroup driver to use...
I0212 10:14:57.191731   66178 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0212 10:14:57.193895   66178 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0212 10:14:57.258375   66178 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0212 10:14:57.300255   66178 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0212 10:14:57.336406   66178 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I0212 10:14:57.336534   66178 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0212 10:14:57.371304   66178 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0212 10:14:57.406019   66178 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0212 10:14:57.441511   66178 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0212 10:14:57.477200   66178 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0212 10:14:57.510641   66178 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0212 10:14:57.544670   66178 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0212 10:14:57.580827   66178 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0212 10:14:57.613070   66178 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0212 10:14:57.765559   66178 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0212 10:14:57.910656   66178 start.go:472] detecting cgroup driver to use...
I0212 10:14:57.910716   66178 detect.go:196] detected "cgroupfs" cgroup driver on host os
I0212 10:14:57.912222   66178 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0212 10:14:57.960788   66178 cruntime.go:279] skipping containerd shutdown because we are bound to it
I0212 10:14:57.960930   66178 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0212 10:14:58.016937   66178 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0212 10:14:58.096031   66178 ssh_runner.go:195] Run: which cri-dockerd
I0212 10:14:58.108321   66178 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0212 10:14:58.175486   66178 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0212 10:14:58.299482   66178 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0212 10:14:58.533664   66178 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0212 10:14:58.732625   66178 docker.go:560] configuring docker to use "cgroupfs" as cgroup driver...
I0212 10:14:58.732933   66178 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (130 bytes)
I0212 10:14:58.815019   66178 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0212 10:14:58.982621   66178 ssh_runner.go:195] Run: sudo systemctl restart docker
I0212 10:14:59.813113   66178 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0212 10:14:59.954681   66178 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0212 10:15:00.133855   66178 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0212 10:15:00.278649   66178 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0212 10:15:00.425972   66178 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0212 10:15:00.481173   66178 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0212 10:15:00.632742   66178 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0212 10:15:01.574011   66178 start.go:519] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0212 10:15:01.575329   66178 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0212 10:15:01.589863   66178 start.go:540] Will wait 60s for crictl version
I0212 10:15:01.590041   66178 ssh_runner.go:195] Run: which crictl
I0212 10:15:01.602939   66178 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0212 10:15:02.335724   66178 start.go:556] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  24.0.7
RuntimeApiVersion:  v1
I0212 10:15:02.335851   66178 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0212 10:15:02.714382   66178 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0212 10:15:02.804044   66178 out.go:204] 🐳  Preparing Kubernetes v1.28.3 on Docker 24.0.7 ...
I0212 10:15:02.805316   66178 cli_runner.go:164] Run: docker exec -t minikube dig +short host.docker.internal
I0212 10:15:03.650215   66178 network.go:96] got host ip for mount in container by digging dns: 192.168.65.254
I0212 10:15:03.651047   66178 ssh_runner.go:195] Run: grep 192.168.65.254	host.minikube.internal$ /etc/hosts
I0212 10:15:03.673981   66178 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.65.254	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0212 10:15:03.782146   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0212 10:15:04.004894   66178 preload.go:132] Checking if preload exists for k8s version v1.28.3 and runtime docker
I0212 10:15:04.005117   66178 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0212 10:15:04.056520   66178 docker.go:671] Got preloaded images: -- stdout --
quay.io/prometheus-operator/prometheus-config-reloader:v0.71.2
quay.io/prometheus-operator/prometheus-operator:v0.71.2
grafana/grafana:10.3.1
mysql:8.0
quay.io/prometheus/prometheus:v2.49.1
mysql:5.7
quay.io/prometheus/node-exporter:v1.7.0
registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.1
registry.k8s.io/kube-apiserver:v1.28.3
registry.k8s.io/kube-controller-manager:v1.28.3
registry.k8s.io/kube-scheduler:v1.28.3
registry.k8s.io/kube-proxy:v1.28.3
quay.io/kiwigrid/k8s-sidecar:1.25.2
quay.io/prometheus/alertmanager:v0.26.0
registry.k8s.io/etcd:3.5.9-0
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5
nginx:1.16.0

-- /stdout --
I0212 10:15:04.058157   66178 docker.go:601] Images already preloaded, skipping extraction
I0212 10:15:04.058693   66178 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0212 10:15:04.152372   66178 docker.go:671] Got preloaded images: -- stdout --
quay.io/prometheus-operator/prometheus-config-reloader:v0.71.2
quay.io/prometheus-operator/prometheus-operator:v0.71.2
grafana/grafana:10.3.1
mysql:8.0
quay.io/prometheus/prometheus:v2.49.1
mysql:5.7
quay.io/prometheus/node-exporter:v1.7.0
registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.1
registry.k8s.io/kube-apiserver:v1.28.3
registry.k8s.io/kube-controller-manager:v1.28.3
registry.k8s.io/kube-scheduler:v1.28.3
registry.k8s.io/kube-proxy:v1.28.3
quay.io/kiwigrid/k8s-sidecar:1.25.2
quay.io/prometheus/alertmanager:v0.26.0
registry.k8s.io/etcd:3.5.9-0
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6
registry.k8s.io/pause:3.9
gcr.io/k8s-minikube/storage-provisioner:v5
nginx:1.16.0

-- /stdout --
I0212 10:15:04.153523   66178 cache_images.go:84] Images are preloaded, skipping loading
I0212 10:15:04.154194   66178 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0212 10:15:04.919858   66178 cni.go:84] Creating CNI manager for ""
I0212 10:15:04.919909   66178 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0212 10:15:04.921666   66178 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0212 10:15:04.921746   66178 kubeadm.go:176] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.28.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0212 10:15:04.922291   66178 kubeadm.go:181] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.28.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0212 10:15:04.924624   66178 kubeadm.go:976] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.28.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0212 10:15:04.924725   66178 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.28.3
I0212 10:15:04.966960   66178 binaries.go:44] Found k8s binaries, skipping transfer
I0212 10:15:04.967080   66178 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0212 10:15:04.998198   66178 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (369 bytes)
I0212 10:15:05.057597   66178 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0212 10:15:05.121037   66178 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2091 bytes)
I0212 10:15:05.185466   66178 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0212 10:15:05.196054   66178 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0212 10:15:05.234661   66178 certs.go:56] Setting up /Users/yaswitha/.minikube/profiles/minikube for IP: 192.168.49.2
I0212 10:15:05.234714   66178 certs.go:190] acquiring lock for shared ca certs: {Name:mkda34a008c6837355ac465172cd0b51a00f61d9 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0212 10:15:05.240092   66178 certs.go:199] skipping minikubeCA CA generation: /Users/yaswitha/.minikube/ca.key
I0212 10:15:05.281517   66178 certs.go:199] skipping proxyClientCA CA generation: /Users/yaswitha/.minikube/proxy-client-ca.key
I0212 10:15:05.283378   66178 certs.go:315] skipping minikube-user signed cert generation: /Users/yaswitha/.minikube/profiles/minikube/client.key
I0212 10:15:05.324277   66178 certs.go:315] skipping minikube signed cert generation: /Users/yaswitha/.minikube/profiles/minikube/apiserver.key.dd3b5fb2
I0212 10:15:05.327706   66178 certs.go:315] skipping aggregator signed cert generation: /Users/yaswitha/.minikube/profiles/minikube/proxy-client.key
I0212 10:15:05.332955   66178 certs.go:437] found cert: /Users/yaswitha/.minikube/certs/Users/yaswitha/.minikube/certs/ca-key.pem (1679 bytes)
I0212 10:15:05.334541   66178 certs.go:437] found cert: /Users/yaswitha/.minikube/certs/Users/yaswitha/.minikube/certs/ca.pem (1082 bytes)
I0212 10:15:05.334849   66178 certs.go:437] found cert: /Users/yaswitha/.minikube/certs/Users/yaswitha/.minikube/certs/cert.pem (1127 bytes)
I0212 10:15:05.336170   66178 certs.go:437] found cert: /Users/yaswitha/.minikube/certs/Users/yaswitha/.minikube/certs/key.pem (1675 bytes)
I0212 10:15:05.342708   66178 ssh_runner.go:362] scp /Users/yaswitha/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0212 10:15:05.430646   66178 ssh_runner.go:362] scp /Users/yaswitha/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1675 bytes)
I0212 10:15:05.517215   66178 ssh_runner.go:362] scp /Users/yaswitha/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0212 10:15:05.605912   66178 ssh_runner.go:362] scp /Users/yaswitha/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0212 10:15:05.716960   66178 ssh_runner.go:362] scp /Users/yaswitha/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0212 10:15:05.832919   66178 ssh_runner.go:362] scp /Users/yaswitha/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0212 10:15:05.919347   66178 ssh_runner.go:362] scp /Users/yaswitha/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0212 10:15:06.017864   66178 ssh_runner.go:362] scp /Users/yaswitha/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I0212 10:15:06.106241   66178 ssh_runner.go:362] scp /Users/yaswitha/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0212 10:15:06.192739   66178 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0212 10:15:06.258365   66178 ssh_runner.go:195] Run: openssl version
I0212 10:15:06.285915   66178 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0212 10:15:06.325888   66178 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0212 10:15:06.341151   66178 certs.go:480] hashing: -rw-r--r-- 1 root root 1111 Feb  4 06:55 /usr/share/ca-certificates/minikubeCA.pem
I0212 10:15:06.341244   66178 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0212 10:15:06.357624   66178 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0212 10:15:06.394750   66178 ssh_runner.go:195] Run: ls /var/lib/minikube/certs/etcd
I0212 10:15:06.406235   66178 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I0212 10:15:06.422385   66178 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I0212 10:15:06.438330   66178 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I0212 10:15:06.455759   66178 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I0212 10:15:06.475090   66178 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I0212 10:15:06.495878   66178 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I0212 10:15:06.514341   66178 kubeadm.go:404] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0212 10:15:06.514501   66178 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0212 10:15:06.562032   66178 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0212 10:15:06.596979   66178 kubeadm.go:419] found existing configuration files, will attempt cluster restart
I0212 10:15:06.598101   66178 kubeadm.go:636] restartCluster start
I0212 10:15:06.598226   66178 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0212 10:15:06.630895   66178 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0212 10:15:06.631012   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0212 10:15:06.740387   66178 kubeconfig.go:92] found "minikube" server: "https://127.0.0.1:56896"
I0212 10:15:06.740409   66178 kubeconfig.go:135] verify returned: got: 127.0.0.1:56896, want: 127.0.0.1:60874
I0212 10:15:06.742110   66178 lock.go:35] WriteFile acquiring /Users/yaswitha/.kube/config: {Name:mk189ae64b0382c9a980228bfb8a7099358d916d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0212 10:15:06.768573   66178 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0212 10:15:06.808057   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:06.808236   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:06.851954   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:06.852019   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:06.852281   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:06.890685   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:07.392010   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:07.392211   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:07.428665   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:07.890865   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:07.890960   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:07.942782   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:08.391617   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:08.391825   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:08.425811   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:08.891097   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:08.891386   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:08.925858   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:09.391361   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:09.391501   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:09.424884   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:09.891883   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:09.892003   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:09.932950   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:10.391088   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:10.391236   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:10.426892   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:10.891609   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:10.891715   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:10.929095   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:11.391579   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:11.391710   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:11.427910   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:11.891777   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:11.892010   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:11.925881   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:12.391566   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:12.391730   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:12.428812   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:12.891523   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:12.892866   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:12.926933   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:13.391298   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:13.391395   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:13.426576   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:13.891513   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:13.891625   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:13.931989   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:14.391221   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:14.391400   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:14.430615   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:14.891500   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:14.891736   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:14.925849   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:15.392152   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:15.392441   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:15.427126   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:15.892233   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:15.892413   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:15.934876   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:16.391304   66178 api_server.go:166] Checking apiserver status ...
I0212 10:15:16.391446   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0212 10:15:16.429937   66178 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0212 10:15:16.809421   66178 kubeadm.go:611] needs reconfigure: apiserver error: context deadline exceeded
I0212 10:15:16.809466   66178 kubeadm.go:1128] stopping kube-system containers ...
I0212 10:15:16.809584   66178 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0212 10:15:16.863760   66178 docker.go:469] Stopping containers: [d3248816cd84 6ba2f8f31113 7cf0ce89afca ce6681fe1920 815fd9a81731 9a2f77d8a33f c4b17568ce66 95b00de29d3d faee097e5583 12002bc09842 b0c18930c6c8 f9fcabae68d3 99f82462c8ff b3d53e32193b 2cb4f44e36c5 9b90409337dc a819c6cbaf76 e2b744d96ed2 25c3b6472a62 b4567c5eb48e e5e0e36f4c9e aa37db08a1ae b85c337c765a 1c3e2a5bf380 7b69a0b684ba 71b16833b9cc 8f114bd3e984]
I0212 10:15:16.863921   66178 ssh_runner.go:195] Run: docker stop d3248816cd84 6ba2f8f31113 7cf0ce89afca ce6681fe1920 815fd9a81731 9a2f77d8a33f c4b17568ce66 95b00de29d3d faee097e5583 12002bc09842 b0c18930c6c8 f9fcabae68d3 99f82462c8ff b3d53e32193b 2cb4f44e36c5 9b90409337dc a819c6cbaf76 e2b744d96ed2 25c3b6472a62 b4567c5eb48e e5e0e36f4c9e aa37db08a1ae b85c337c765a 1c3e2a5bf380 7b69a0b684ba 71b16833b9cc 8f114bd3e984
I0212 10:15:16.914925   66178 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I0212 10:15:16.953989   66178 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0212 10:15:16.988349   66178 kubeadm.go:155] found existing configuration files:
-rw------- 1 root root 5639 Feb  7 05:00 /etc/kubernetes/admin.conf
-rw------- 1 root root 5656 Feb 10 01:04 /etc/kubernetes/controller-manager.conf
-rw------- 1 root root 1971 Feb  7 05:00 /etc/kubernetes/kubelet.conf
-rw------- 1 root root 5600 Feb 10 01:04 /etc/kubernetes/scheduler.conf

I0212 10:15:16.988501   66178 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf
I0212 10:15:17.024296   66178 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf
I0212 10:15:17.061575   66178 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf
I0212 10:15:17.095084   66178 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/controller-manager.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf: Process exited with status 1
stdout:

stderr:
I0212 10:15:17.095185   66178 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/controller-manager.conf
I0212 10:15:17.126839   66178 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf
I0212 10:15:17.159913   66178 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/scheduler.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf: Process exited with status 1
stdout:

stderr:
I0212 10:15:17.160004   66178 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/scheduler.conf
I0212 10:15:17.199077   66178 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0212 10:15:17.231330   66178 kubeadm.go:713] reconfiguring cluster from /var/tmp/minikube/kubeadm.yaml
I0212 10:15:17.231345   66178 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I0212 10:15:17.987684   66178 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I0212 10:15:19.106327   66178 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml": (1.118565215s)
I0212 10:15:19.106351   66178 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I0212 10:15:19.397851   66178 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I0212 10:15:19.538802   66178 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I0212 10:15:19.663547   66178 api_server.go:52] waiting for apiserver process to appear ...
I0212 10:15:19.663655   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0212 10:15:19.705071   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0212 10:15:20.253063   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0212 10:15:20.753063   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0212 10:15:21.253389   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0212 10:15:21.753797   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0212 10:15:22.253167   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0212 10:15:22.753214   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0212 10:15:23.253313   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0212 10:15:23.753622   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0212 10:15:24.253376   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0212 10:15:24.584054   66178 api_server.go:72] duration metric: took 4.920356494s to wait for apiserver process to appear ...
I0212 10:15:24.584113   66178 api_server.go:88] waiting for apiserver healthz status ...
I0212 10:15:24.584532   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:24.597366   66178 api_server.go:269] stopped: https://127.0.0.1:60874/healthz: Get "https://127.0.0.1:60874/healthz": EOF
I0212 10:15:24.597492   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:24.605566   66178 api_server.go:269] stopped: https://127.0.0.1:60874/healthz: Get "https://127.0.0.1:60874/healthz": EOF
I0212 10:15:25.106347   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:25.133954   66178 api_server.go:269] stopped: https://127.0.0.1:60874/healthz: Get "https://127.0.0.1:60874/healthz": EOF
I0212 10:15:25.606558   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:25.619804   66178 api_server.go:269] stopped: https://127.0.0.1:60874/healthz: Get "https://127.0.0.1:60874/healthz": EOF
I0212 10:15:26.106011   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:26.127688   66178 api_server.go:269] stopped: https://127.0.0.1:60874/healthz: Get "https://127.0.0.1:60874/healthz": EOF
I0212 10:15:26.609375   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:26.633812   66178 api_server.go:269] stopped: https://127.0.0.1:60874/healthz: Get "https://127.0.0.1:60874/healthz": EOF
I0212 10:15:27.105861   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:27.166624   66178 api_server.go:269] stopped: https://127.0.0.1:60874/healthz: Get "https://127.0.0.1:60874/healthz": EOF
I0212 10:15:27.605824   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:27.610752   66178 api_server.go:269] stopped: https://127.0.0.1:60874/healthz: Get "https://127.0.0.1:60874/healthz": EOF
I0212 10:15:28.106615   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:28.112395   66178 api_server.go:269] stopped: https://127.0.0.1:60874/healthz: Get "https://127.0.0.1:60874/healthz": EOF
I0212 10:15:28.605958   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:33.607728   66178 api_server.go:269] stopped: https://127.0.0.1:60874/healthz: Get "https://127.0.0.1:60874/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0212 10:15:33.607971   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:37.587823   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W0212 10:15:37.588195   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0212 10:15:37.588245   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:37.732415   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W0212 10:15:37.732756   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0212 10:15:37.732768   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:37.796482   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W0212 10:15:37.796508   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0212 10:15:38.107179   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:38.198295   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[-]poststarthook/start-apiextensions-controllers failed: reason withheld
[-]poststarthook/crd-informer-synced failed: reason withheld
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0212 10:15:38.198357   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[-]poststarthook/start-apiextensions-controllers failed: reason withheld
[-]poststarthook/crd-informer-synced failed: reason withheld
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0212 10:15:38.607065   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:39.034045   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0212 10:15:39.034079   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0212 10:15:39.106293   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:39.199816   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0212 10:15:39.199852   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0212 10:15:39.606697   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:39.714758   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0212 10:15:39.714792   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0212 10:15:40.106456   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:40.678827   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0212 10:15:40.678866   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0212 10:15:40.678884   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:40.713416   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0212 10:15:40.713467   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0212 10:15:41.106412   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:41.212643   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0212 10:15:41.212674   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0212 10:15:41.606317   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:41.710205   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0212 10:15:41.710236   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0212 10:15:42.106945   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:42.206985   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0212 10:15:42.207016   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0212 10:15:42.606368   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:42.634548   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0212 10:15:42.634593   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0212 10:15:43.107779   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:43.182467   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0212 10:15:43.182504   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0212 10:15:43.606310   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:43.635838   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0212 10:15:43.635880   66178 api_server.go:103] status: https://127.0.0.1:60874/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0212 10:15:44.106540   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:15:44.149488   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 200:
ok
I0212 10:15:44.212456   66178 api_server.go:141] control plane version: v1.28.3
I0212 10:15:44.212496   66178 api_server.go:131] duration metric: took 19.627784912s to wait for apiserver health ...
I0212 10:15:44.212668   66178 cni.go:84] Creating CNI manager for ""
I0212 10:15:44.212739   66178 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0212 10:15:44.226114   66178 out.go:177] 🔗  Configuring bridge CNI (Container Networking Interface) ...
I0212 10:15:44.245391   66178 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I0212 10:15:44.397100   66178 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (457 bytes)
I0212 10:15:44.725096   66178 system_pods.go:43] waiting for kube-system pods to appear ...
I0212 10:15:44.915852   66178 system_pods.go:59] 7 kube-system pods found
I0212 10:15:44.916258   66178 system_pods.go:61] "coredns-5dd5756b68-jdzlt" [feb8b6fb-936b-4dcb-9b16-a852e25e4b7b] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I0212 10:15:44.916274   66178 system_pods.go:61] "etcd-minikube" [86f1298b-72f0-4e88-9d82-f98230e2870a] Running
I0212 10:15:44.916315   66178 system_pods.go:61] "kube-apiserver-minikube" [4ff2efef-e938-4fb0-a750-8caa1bf15092] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I0212 10:15:44.916328   66178 system_pods.go:61] "kube-controller-manager-minikube" [ded0e903-acb9-4f75-8e08-625798e919d1] Running
I0212 10:15:44.916355   66178 system_pods.go:61] "kube-proxy-mc9jh" [3f02015e-5657-4f23-83de-402b7622a49f] Running / Ready:ContainersNotReady (containers with unready status: [kube-proxy]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-proxy])
I0212 10:15:44.916365   66178 system_pods.go:61] "kube-scheduler-minikube" [a80aa674-6c30-45bc-b914-cdf86d7bcf9b] Running
I0212 10:15:44.916383   66178 system_pods.go:61] "storage-provisioner" [56107894-73e2-4bd4-b2be-3d125a948f17] Running / Ready:ContainersNotReady (containers with unready status: [storage-provisioner]) / ContainersReady:ContainersNotReady (containers with unready status: [storage-provisioner])
I0212 10:15:44.916391   66178 system_pods.go:74] duration metric: took 191.272777ms to wait for pod list to return data ...
I0212 10:15:44.916401   66178 node_conditions.go:102] verifying NodePressure condition ...
I0212 10:15:45.010201   66178 node_conditions.go:122] node storage ephemeral capacity is 61202244Ki
I0212 10:15:45.010232   66178 node_conditions.go:123] node cpu capacity is 4
I0212 10:15:45.010476   66178 node_conditions.go:105] duration metric: took 94.06037ms to run NodePressure ...
I0212 10:15:45.010785   66178 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml"
I0212 10:15:47.807265   66178 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml": (2.796198892s)
I0212 10:15:47.807449   66178 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0212 10:15:47.915841   66178 ops.go:34] apiserver oom_adj: -16
I0212 10:15:47.915940   66178 kubeadm.go:640] restartCluster took 41.31653693s
I0212 10:15:47.915957   66178 kubeadm.go:406] StartCluster complete in 41.400399847s
I0212 10:15:47.916475   66178 settings.go:142] acquiring lock: {Name:mk2d2269f49b3eceafdbd4be74e3b1e411b7a2ff Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0212 10:15:47.920114   66178 settings.go:150] Updating kubeconfig:  /Users/yaswitha/.kube/config
I0212 10:15:47.928743   66178 lock.go:35] WriteFile acquiring /Users/yaswitha/.kube/config: {Name:mk189ae64b0382c9a980228bfb8a7099358d916d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0212 10:15:47.934146   66178 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0212 10:15:47.934118   66178 addons.go:499] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volumesnapshots:false]
I0212 10:15:47.934342   66178 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0212 10:15:47.934391   66178 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0212 10:15:47.934405   66178 addons.go:231] Setting addon storage-provisioner=true in "minikube"
W0212 10:15:47.934415   66178 addons.go:240] addon storage-provisioner should already be in state true
I0212 10:15:47.934415   66178 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0212 10:15:47.935741   66178 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0212 10:15:47.937108   66178 host.go:66] Checking if "minikube" exists ...
I0212 10:15:47.947101   66178 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0212 10:15:47.948570   66178 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0212 10:15:48.059918   66178 kapi.go:248] "coredns" deployment in "kube-system" namespace and "minikube" context rescaled to 1 replicas
I0212 10:15:48.060330   66178 start.go:223] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0212 10:15:48.078234   66178 out.go:177] 🔎  Verifying Kubernetes components...
I0212 10:15:48.107417   66178 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0212 10:15:48.278823   66178 out.go:177]     ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0212 10:15:48.271641   66178 addons.go:231] Setting addon default-storageclass=true in "minikube"
W0212 10:15:48.278884   66178 addons.go:240] addon default-storageclass should already be in state true
I0212 10:15:48.293405   66178 host.go:66] Checking if "minikube" exists ...
I0212 10:15:48.294036   66178 addons.go:423] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0212 10:15:48.294051   66178 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0212 10:15:48.294191   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0212 10:15:48.303380   66178 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0212 10:15:48.510943   66178 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60875 SSHKeyPath:/Users/yaswitha/.minikube/machines/minikube/id_rsa Username:docker}
I0212 10:15:48.539127   66178 addons.go:423] installing /etc/kubernetes/addons/storageclass.yaml
I0212 10:15:48.539144   66178 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0212 10:15:48.539289   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0212 10:15:48.702890   66178 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:60875 SSHKeyPath:/Users/yaswitha/.minikube/machines/minikube/id_rsa Username:docker}
I0212 10:15:49.499487   66178 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0212 10:15:49.507198   66178 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0212 10:15:51.408557   66178 ssh_runner.go:235] Completed: sudo systemctl is-active --quiet service kubelet: (3.301002237s)
I0212 10:15:51.408685   66178 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0212 10:15:51.410552   66178 ssh_runner.go:235] Completed: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml": (3.476181128s)
I0212 10:15:51.412506   66178 start.go:899] CoreDNS already contains "host.minikube.internal" host record, skipping...
I0212 10:15:51.567862   66178 api_server.go:52] waiting for apiserver process to appear ...
I0212 10:15:51.568001   66178 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0212 10:16:00.591747   66178 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: (11.091814904s)
I0212 10:16:00.592183   66178 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: (11.084584518s)
I0212 10:16:00.592392   66178 ssh_runner.go:235] Completed: sudo pgrep -xnf kube-apiserver.*minikube.*: (9.02406935s)
I0212 10:16:00.592482   66178 api_server.go:72] duration metric: took 12.531635243s to wait for apiserver process to appear ...
I0212 10:16:00.592522   66178 api_server.go:88] waiting for apiserver healthz status ...
I0212 10:16:00.592579   66178 api_server.go:253] Checking apiserver healthz at https://127.0.0.1:60874/healthz ...
I0212 10:16:00.643603   66178 api_server.go:279] https://127.0.0.1:60874/healthz returned 200:
ok
I0212 10:16:00.688592   66178 api_server.go:141] control plane version: v1.28.3
I0212 10:16:00.688611   66178 api_server.go:131] duration metric: took 96.078165ms to wait for apiserver health ...
I0212 10:16:00.688638   66178 system_pods.go:43] waiting for kube-system pods to appear ...
I0212 10:16:00.724979   66178 out.go:177] 🌟  Enabled addons: storage-provisioner, default-storageclass
I0212 10:16:00.722728   66178 system_pods.go:59] 7 kube-system pods found
I0212 10:16:00.742944   66178 addons.go:502] enable addons completed in 12.810157562s: enabled=[storage-provisioner default-storageclass]
I0212 10:16:00.725140   66178 system_pods.go:61] "coredns-5dd5756b68-jdzlt" [feb8b6fb-936b-4dcb-9b16-a852e25e4b7b] Running
I0212 10:16:00.743022   66178 system_pods.go:61] "etcd-minikube" [86f1298b-72f0-4e88-9d82-f98230e2870a] Running
I0212 10:16:00.743036   66178 system_pods.go:61] "kube-apiserver-minikube" [4ff2efef-e938-4fb0-a750-8caa1bf15092] Running
I0212 10:16:00.743053   66178 system_pods.go:61] "kube-controller-manager-minikube" [ded0e903-acb9-4f75-8e08-625798e919d1] Running
I0212 10:16:00.743065   66178 system_pods.go:61] "kube-proxy-mc9jh" [3f02015e-5657-4f23-83de-402b7622a49f] Running
I0212 10:16:00.743086   66178 system_pods.go:61] "kube-scheduler-minikube" [a80aa674-6c30-45bc-b914-cdf86d7bcf9b] Running
I0212 10:16:00.743116   66178 system_pods.go:61] "storage-provisioner" [56107894-73e2-4bd4-b2be-3d125a948f17] Running / Ready:ContainersNotReady (containers with unready status: [storage-provisioner]) / ContainersReady:ContainersNotReady (containers with unready status: [storage-provisioner])
I0212 10:16:00.743196   66178 system_pods.go:74] duration metric: took 54.478474ms to wait for pod list to return data ...
I0212 10:16:00.743271   66178 kubeadm.go:581] duration metric: took 12.682413885s to wait for : map[apiserver:true system_pods:true] ...
I0212 10:16:00.743299   66178 node_conditions.go:102] verifying NodePressure condition ...
I0212 10:16:00.803860   66178 node_conditions.go:122] node storage ephemeral capacity is 61202244Ki
I0212 10:16:00.803878   66178 node_conditions.go:123] node cpu capacity is 4
I0212 10:16:00.803905   66178 node_conditions.go:105] duration metric: took 60.594645ms to run NodePressure ...
I0212 10:16:00.803923   66178 start.go:228] waiting for startup goroutines ...
I0212 10:16:00.803937   66178 start.go:233] waiting for cluster config update ...
I0212 10:16:00.803989   66178 start.go:242] writing updated cluster config ...
I0212 10:16:00.807232   66178 ssh_runner.go:195] Run: rm -f paused
I0212 10:16:00.970495   66178 start.go:600] kubectl: 1.29.1, cluster: 1.28.3 (minor skew: 1)
I0212 10:16:00.994628   66178 out.go:177] 🏄  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

* 
* ==> Docker <==
* Feb 12 02:58:12 minikube dockerd[785]: time="2024-02-12T02:58:12.075177487Z" level=info msg="ignoring event" container=2f61a2e2a88d90a2b1f746ce5a46086d5f9aeb8203feda4019c279c78ce9944f module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:17 minikube cri-dockerd[1020]: time="2024-02-12T02:58:17Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/5ca6ae21aef097cece45f1641a818f7a03bf54f984c09d3251ef61575907ad84/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:58:20 minikube dockerd[785]: time="2024-02-12T02:58:20.005380259Z" level=info msg="ignoring event" container=de1e568d3265adbd3dfdf161aaea751377412be9d0a834d4f27161c82d95ed13 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:20 minikube dockerd[785]: time="2024-02-12T02:58:20.595095489Z" level=info msg="ignoring event" container=5ca6ae21aef097cece45f1641a818f7a03bf54f984c09d3251ef61575907ad84 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:25 minikube cri-dockerd[1020]: time="2024-02-12T02:58:25Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/737ba9ebce210ba45a9e32a5e7114ccfca5e1e4896c91952e1eccb716585f106/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:58:26 minikube dockerd[785]: time="2024-02-12T02:58:26.671117717Z" level=info msg="ignoring event" container=b914321e5aac43b13da84bae74eb5d18e1429988f5a2a183e3aef9bb71820ed1 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:27 minikube dockerd[785]: time="2024-02-12T02:58:27.220242422Z" level=info msg="ignoring event" container=737ba9ebce210ba45a9e32a5e7114ccfca5e1e4896c91952e1eccb716585f106 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:30 minikube cri-dockerd[1020]: time="2024-02-12T02:58:30Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/1fa3f07ecafb850984ee69b9ec9a372e6a2eedfed155bada9a7c6f2481eca15f/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:58:31 minikube dockerd[785]: time="2024-02-12T02:58:31.814891041Z" level=info msg="ignoring event" container=ccf409ea3cc7a3f92c0fd9ae86027feaebe310a897f88a7cab4b926967851380 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:36 minikube dockerd[785]: time="2024-02-12T02:58:36.793461317Z" level=info msg="ignoring event" container=ffc02154cafafa4215f47106cf8682637777530f6288b7091d612a9bd8ecc543 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:37 minikube dockerd[785]: time="2024-02-12T02:58:37.170566306Z" level=info msg="ignoring event" container=39a31259d0ec60d61037be0e84d905cfda3e4b49ab6958d40ca02e139df4bdca module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:37 minikube dockerd[785]: time="2024-02-12T02:58:37.368646011Z" level=info msg="ignoring event" container=09f694aba841d65e0dbd7f7638c7b5120002df611526a7b63d62154eebf44937 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:38 minikube cri-dockerd[1020]: time="2024-02-12T02:58:38Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"alertmanager-stable-kube-prometheus-sta-alertmanager-0_monitoring\": unexpected command output nsenter: cannot open /proc/171724/ns/net: No such file or directory\n with error: exit status 1"
Feb 12 02:58:38 minikube dockerd[785]: time="2024-02-12T02:58:38.168356784Z" level=info msg="ignoring event" container=149b4bacf975a8b7bc306b57c03465a33bcd5616457da64e67fb945b6264a4d3 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:38 minikube dockerd[785]: time="2024-02-12T02:58:38.208637845Z" level=info msg="ignoring event" container=1fa3f07ecafb850984ee69b9ec9a372e6a2eedfed155bada9a7c6f2481eca15f module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:42 minikube cri-dockerd[1020]: time="2024-02-12T02:58:42Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/1df872f8a056e9ebe34dee045a34c7a4ec10ee527fcd7445f9b10e433da85e2a/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:58:42 minikube cri-dockerd[1020]: time="2024-02-12T02:58:42Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/c6971136e93bcdb5225bcf6687fb38479692ebd001268b14894c1d2a86faf7b8/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:58:46 minikube dockerd[785]: time="2024-02-12T02:58:46.007107513Z" level=info msg="ignoring event" container=b305c760a5b45278f2ba056c41cc1320b2b434b30213477c0bb694ff57d5e3d8 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:46 minikube dockerd[785]: time="2024-02-12T02:58:46.414978746Z" level=info msg="ignoring event" container=1df872f8a056e9ebe34dee045a34c7a4ec10ee527fcd7445f9b10e433da85e2a module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:53 minikube cri-dockerd[1020]: time="2024-02-12T02:58:53Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/fc562a62246f216c5d7e27dbcaf1216a44c46107e43864a432cad82da9c65026/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:58:54 minikube dockerd[785]: time="2024-02-12T02:58:54.423414292Z" level=info msg="ignoring event" container=97aa3762d851041d33d3eaa5bb98f12e1d17528bcb2d8196c3777550c58d8fc9 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:58:54 minikube dockerd[785]: time="2024-02-12T02:58:54.822364957Z" level=info msg="ignoring event" container=fc562a62246f216c5d7e27dbcaf1216a44c46107e43864a432cad82da9c65026 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:01 minikube cri-dockerd[1020]: time="2024-02-12T02:59:01Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/b38c764904adbe4b94b5170ae1e1abd037f200443ec9cc2dfb51cf8b4d80369d/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:59:03 minikube dockerd[785]: time="2024-02-12T02:59:03.840529683Z" level=info msg="ignoring event" container=44b8516a9bd23ac5e876d547b6b537940332e13c5343333e00fd7beace6ca7b1 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:04 minikube dockerd[785]: time="2024-02-12T02:59:04.188389714Z" level=info msg="ignoring event" container=b38c764904adbe4b94b5170ae1e1abd037f200443ec9cc2dfb51cf8b4d80369d module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:07 minikube cri-dockerd[1020]: time="2024-02-12T02:59:07Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/0e1407cea2c997c1919f4f13ecefccb18363ff5e46fc5bd2536aabe0e4e1fa2a/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:59:11 minikube dockerd[785]: time="2024-02-12T02:59:11.419391575Z" level=info msg="ignoring event" container=e5e4a67100a476750ed94bfcb588378e0d7471962cff4edfbe4399784acd7e99 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:11 minikube dockerd[785]: time="2024-02-12T02:59:11.902728150Z" level=info msg="ignoring event" container=0e1407cea2c997c1919f4f13ecefccb18363ff5e46fc5bd2536aabe0e4e1fa2a module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:15 minikube cri-dockerd[1020]: time="2024-02-12T02:59:15Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/70d4ad09e58bb5e25348de0aea1e53ce497b410bd590ab3a067b970f3da75952/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:59:18 minikube dockerd[785]: time="2024-02-12T02:59:18.169212507Z" level=info msg="ignoring event" container=203d2cf799dae9600072733f8e3bc9ea7a4e25e94e295a6b6fa384f31497a9a9 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:18 minikube dockerd[785]: time="2024-02-12T02:59:18.597044302Z" level=info msg="ignoring event" container=c6971136e93bcdb5225bcf6687fb38479692ebd001268b14894c1d2a86faf7b8 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:23 minikube cri-dockerd[1020]: time="2024-02-12T02:59:23Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/325964cd20c5b4b72e7cd470e5cc0a1251a051bd05ad15223e608e4a040f294d/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:59:24 minikube dockerd[785]: time="2024-02-12T02:59:24.389271288Z" level=info msg="ignoring event" container=05a6af8fe177159d587355ed98785405fe8059e69234ea88b97bb3100721cf90 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:28 minikube dockerd[785]: time="2024-02-12T02:59:28.463432845Z" level=info msg="ignoring event" container=ada0902b33cde4992b03146d12e8a402acd23b7804fdb9370f2b67af499cec0d module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:28 minikube dockerd[785]: time="2024-02-12T02:59:28.479439050Z" level=info msg="ignoring event" container=9a9b412bb621e8c5a40bada1b75311f741b0363d947b77335662e3848e1b37b2 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:29 minikube dockerd[785]: time="2024-02-12T02:59:29.006594876Z" level=info msg="ignoring event" container=325964cd20c5b4b72e7cd470e5cc0a1251a051bd05ad15223e608e4a040f294d module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:32 minikube cri-dockerd[1020]: time="2024-02-12T02:59:32Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/d696a8e651314e098a8a75d6437e6f6d5ff901a5a127a9eb9bbf597987a10239/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:59:35 minikube dockerd[785]: time="2024-02-12T02:59:35.802404353Z" level=info msg="ignoring event" container=6a42b06fab97c5947c4f71c68b246fe92f0082a6b7a4fa8c32338a116b74f553 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:37 minikube dockerd[785]: time="2024-02-12T02:59:37.105854799Z" level=info msg="ignoring event" container=d696a8e651314e098a8a75d6437e6f6d5ff901a5a127a9eb9bbf597987a10239 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:41 minikube cri-dockerd[1020]: time="2024-02-12T02:59:41Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/00211fc8337e1a167bda5183a27e84f19e279baee1e77d3acad7f4491233018d/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:59:43 minikube dockerd[785]: time="2024-02-12T02:59:42.999829872Z" level=info msg="ignoring event" container=86ec4d9c4a27c9719b3ed181330a2ec5ab5ae6445da057f1d17450eaeec15fd9 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:43 minikube dockerd[785]: time="2024-02-12T02:59:43.921747775Z" level=info msg="ignoring event" container=00211fc8337e1a167bda5183a27e84f19e279baee1e77d3acad7f4491233018d module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:44 minikube dockerd[785]: time="2024-02-12T02:59:44.221474444Z" level=info msg="ignoring event" container=5aae55c135245c11dc018157f1decd6aa0baa84a9752f280cdaee61b998e58d4 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:44 minikube dockerd[785]: time="2024-02-12T02:59:44.871204100Z" level=info msg="ignoring event" container=70d4ad09e58bb5e25348de0aea1e53ce497b410bd590ab3a067b970f3da75952 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:46 minikube dockerd[785]: time="2024-02-12T02:59:46.889505343Z" level=error msg="Failed to compute size of container rootfs 5aae55c135245c11dc018157f1decd6aa0baa84a9752f280cdaee61b998e58d4: mount does not exist"
Feb 12 02:59:47 minikube cri-dockerd[1020]: time="2024-02-12T02:59:47Z" level=error msg="Error response from daemon: No such container: 5aae55c135245c11dc018157f1decd6aa0baa84a9752f280cdaee61b998e58d4 Failed to get stats from container 5aae55c135245c11dc018157f1decd6aa0baa84a9752f280cdaee61b998e58d4"
Feb 12 02:59:48 minikube cri-dockerd[1020]: time="2024-02-12T02:59:48Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/e2ac61677960d09ec141f02365a23b3fb2f614748c31ad4c2e76a1c62c05e20d/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:59:49 minikube cri-dockerd[1020]: time="2024-02-12T02:59:49Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/1c019f7277778fa702e96d771d5f7aa26c217973de1a1603c0b48c3131191c7e/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:59:51 minikube dockerd[785]: time="2024-02-12T02:59:51.081104392Z" level=info msg="ignoring event" container=c6ccb24a9c971029282ba4ec5985df87ee188a1fced9ffc6338de3b4bc1d2185 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:51 minikube dockerd[785]: time="2024-02-12T02:59:51.225714780Z" level=info msg="ignoring event" container=dde6d617105b5517577a3ba754e25ef19e83388754d9927c3a66b644c942a37d module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:52 minikube dockerd[785]: time="2024-02-12T02:59:52.393719048Z" level=info msg="ignoring event" container=e2ac61677960d09ec141f02365a23b3fb2f614748c31ad4c2e76a1c62c05e20d module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:52 minikube dockerd[785]: time="2024-02-12T02:59:52.393834695Z" level=info msg="ignoring event" container=1c019f7277778fa702e96d771d5f7aa26c217973de1a1603c0b48c3131191c7e module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 02:59:56 minikube cri-dockerd[1020]: time="2024-02-12T02:59:56Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/e30d9d4eaa246c126498d2e1df0db4080801f3f60fb47f315523437e962ab355/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 02:59:56 minikube cri-dockerd[1020]: time="2024-02-12T02:59:56Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/038f0bdbf193e98843196931b6c38ec3a8460c8f94d77e315d17c64e8ffa79a7/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 03:00:01 minikube dockerd[785]: time="2024-02-12T03:00:01.528810862Z" level=info msg="ignoring event" container=e4bf2827fa1024a0c85a6ef13f9acacb7761e6e36358afba636af8509fe77ee7 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 03:00:02 minikube dockerd[785]: time="2024-02-12T03:00:02.174327432Z" level=info msg="ignoring event" container=038f0bdbf193e98843196931b6c38ec3a8460c8f94d77e315d17c64e8ffa79a7 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 03:00:06 minikube cri-dockerd[1020]: time="2024-02-12T03:00:06Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/2f7934b7b29390a036b09caf6927750a212c0307441a8df62f8894d0d5b21feb/resolv.conf as [nameserver 10.96.0.10 search monitoring.svc.cluster.local svc.cluster.local cluster.local options ndots:5]"
Feb 12 03:00:14 minikube dockerd[785]: time="2024-02-12T03:00:14.372122886Z" level=info msg="ignoring event" container=c286a4d9885265a2e602abbd68aebc5fb538560bfb3a5b4f30bd2eed5e19128e module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Feb 12 03:00:15 minikube cri-dockerd[1020]: time="2024-02-12T03:00:15Z" level=info msg="Failed to read pod IP from plugin/docker: networkPlugin cni failed on the status hook for pod \"prometheus-stable-kube-prometheus-sta-prometheus-0_monitoring\": unexpected command output nsenter: cannot open /proc/178493/ns/net: No such file or directory\n with error: exit status 1"
Feb 12 03:00:15 minikube dockerd[785]: time="2024-02-12T03:00:15.618624273Z" level=info msg="ignoring event" container=2f7934b7b29390a036b09caf6927750a212c0307441a8df62f8894d0d5b21feb module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"

* 
* ==> container status <==
* CONTAINER           IMAGE                                                                                                      CREATED             STATE               NAME                      ATTEMPT             POD ID              POD
72c209dbda808       cec0d5e9e3c15                                                                                              22 seconds ago      Running             init-config-reloader      0                   e30d9d4eaa246       alertmanager-stable-kube-prometheus-sta-alertmanager-0
479a6d9a573f0       b6188b3dc37c4                                                                                              20 minutes ago      Running             mysql                     0                   581d9176a8637       mysql-d6f56dd44-w9z58
897a2fb710609       f5f9f4739d5f4                                                                                              44 minutes ago      Running             kube-state-metrics        2                   41120389bfd62       stable-kube-state-metrics-7fdbdb97cb-kvbmr
c393dde5d9c5f       c5762a060a0f4                                                                                              44 minutes ago      Running             prometheus-operator       2                   ab49f73a4b6ea       prometheus-operator-7d5c68dc4-jblgp
22d2cf0d235c1       c5762a060a0f4                                                                                              44 minutes ago      Running             kube-prometheus-stack     2                   17e7571048742       stable-kube-prometheus-sta-operator-c548659cd-zt6rn
180fc8eca507d       6e38f40d628db                                                                                              44 minutes ago      Running             storage-provisioner       10                  a3783f354e571       storage-provisioner
ddb917ad409c0       2fec87cd43629                                                                                              44 minutes ago      Running             grafana                   1                   a75c7ac974e51       stable-grafana-6889bcb489-mgndv
31b38f23190e5       ceb991e912e73                                                                                              44 minutes ago      Running             grafana-sc-datasources    1                   a75c7ac974e51       stable-grafana-6889bcb489-mgndv
94a8378ae6405       f5f9f4739d5f4                                                                                              44 minutes ago      Exited              kube-state-metrics        1                   41120389bfd62       stable-kube-state-metrics-7fdbdb97cb-kvbmr
d1f806ec4f6dd       c5762a060a0f4                                                                                              44 minutes ago      Exited              prometheus-operator       1                   ab49f73a4b6ea       prometheus-operator-7d5c68dc4-jblgp
4553b03552221       ceb991e912e73                                                                                              44 minutes ago      Running             grafana-sc-dashboard      1                   a75c7ac974e51       stable-grafana-6889bcb489-mgndv
18b9b9546feca       c5762a060a0f4                                                                                              44 minutes ago      Exited              kube-prometheus-stack     1                   17e7571048742       stable-kube-prometheus-sta-operator-c548659cd-zt6rn
0538d2acca232       ead0a4a53df89                                                                                              44 minutes ago      Running             coredns                   4                   c2ab48068019d       coredns-5dd5756b68-jdzlt
b4f31634bd88c       6e38f40d628db                                                                                              44 minutes ago      Exited              storage-provisioner       9                   a3783f354e571       storage-provisioner
0bfe65d17ea8c       bfc896cf80fba                                                                                              44 minutes ago      Running             kube-proxy                4                   387341e4cd926       kube-proxy-mc9jh
bd61e0becbca3       72c9c20889862                                                                                              44 minutes ago      Running             node-exporter             1                   b25ae7c40f0c1       stable-prometheus-node-exporter-n8v48
76466e307e84c       6d1b4fd1b182d                                                                                              44 minutes ago      Running             kube-scheduler            4                   51c11592ecc57       kube-scheduler-minikube
c16896f057139       5374347291230                                                                                              44 minutes ago      Running             kube-apiserver            4                   baf99111cab42       kube-apiserver-minikube
6481fa418865e       73deb9a3f7025                                                                                              44 minutes ago      Running             etcd                      4                   3ee3a1d61d1d5       etcd-minikube
ed40fc1b38b6b       10baa1ca17068                                                                                              44 minutes ago      Running             kube-controller-manager   4                   852f241b2ab51       kube-controller-manager-minikube
926511ec1960f       grafana/grafana@sha256:7567a7c70a3c1d75aeeedc968d1304174a16651e55a60d1fb132a05e1e63a054                    43 hours ago        Exited              grafana                   0                   651a5d2c0d823       stable-grafana-6889bcb489-mgndv
d806233757247       ceb991e912e73                                                                                              43 hours ago        Exited              grafana-sc-datasources    0                   651a5d2c0d823       stable-grafana-6889bcb489-mgndv
8befc552cf0c2       quay.io/kiwigrid/k8s-sidecar@sha256:cb4c638ffb1fa1eb49678e0f0423564b39254533f63f4ca6a6c24260472e0c4f       43 hours ago        Exited              grafana-sc-dashboard      0                   651a5d2c0d823       stable-grafana-6889bcb489-mgndv
dc60abd496a18       quay.io/prometheus/node-exporter@sha256:4cb2b9019f1757be8482419002cb7afe028fdba35d47958829e4cfeaf6246d80   43 hours ago        Exited              node-exporter             0                   d14557e263ff0       stable-prometheus-node-exporter-n8v48
6ba2f8f31113c       ead0a4a53df89                                                                                              2 days ago          Exited              coredns                   3                   815fd9a81731f       coredns-5dd5756b68-jdzlt
ce6681fe19206       bfc896cf80fba                                                                                              2 days ago          Exited              kube-proxy                3                   9a2f77d8a33fe       kube-proxy-mc9jh
95b00de29d3d9       73deb9a3f7025                                                                                              2 days ago          Exited              etcd                      3                   b3d53e32193b6       etcd-minikube
faee097e55834       5374347291230                                                                                              2 days ago          Exited              kube-apiserver            3                   f9fcabae68d3f       kube-apiserver-minikube
12002bc09842e       10baa1ca17068                                                                                              2 days ago          Exited              kube-controller-manager   3                   99f82462c8ff9       kube-controller-manager-minikube
b0c18930c6c87       6d1b4fd1b182d                                                                                              2 days ago          Exited              kube-scheduler            3                   2cb4f44e36c54       kube-scheduler-minikube

* 
* ==> coredns [0538d2acca23] <==
* [INFO] 10.244.1.163:55357 - 6267 "A IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.000568877s
[INFO] 10.244.1.163:52955 - 30589 "AAAA IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.000720183s
[INFO] 10.244.1.163:51141 - 13260 "A IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.045581985s
[INFO] 10.244.1.163:46494 - 44496 "AAAA IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.000217737s
[INFO] 10.244.1.163:60368 - 64154 "A IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.000286031s
[INFO] 10.244.1.163:53802 - 23795 "A IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.000220012s
[INFO] 10.244.1.163:51840 - 27273 "A IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.002415129s
[INFO] 10.244.1.163:47393 - 31293 "AAAA IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.001256771s
[INFO] 10.244.1.163:43203 - 46472 "AAAA IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 255 0.058607918s
[INFO] 10.244.1.163:32874 - 40255 "A IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 207 0.058929763s
[INFO] 10.244.1.163:36144 - 45906 "AAAA IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 68 0.061776746s
[INFO] 10.244.1.163:57977 - 39036 "A IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 56 0.065435584s
[INFO] 10.244.1.163:34377 - 23075 "A IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.006482238s
[INFO] 10.244.1.163:40782 - 47627 "AAAA IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.000807408s
[INFO] 10.244.1.163:32936 - 58511 "AAAA IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.000362054s
[INFO] 10.244.1.163:48621 - 64513 "A IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.000887219s
[INFO] 10.244.1.163:37960 - 48231 "AAAA IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000219629s
[INFO] 10.244.1.163:43940 - 52754 "A IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000191608s
[INFO] 10.244.1.163:48468 - 9045 "A IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 207 0.064709045s
[INFO] 10.244.1.163:60578 - 22660 "AAAA IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 255 0.063929468s
[INFO] 10.244.1.163:53741 - 52394 "AAAA IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.000203266s
[INFO] 10.244.1.163:57712 - 49671 "A IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.000217507s
[INFO] 10.244.1.163:55291 - 9195 "A IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.000391267s
[INFO] 10.244.1.163:36644 - 1131 "AAAA IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.000285416s
[INFO] 10.244.1.163:60433 - 37353 "AAAA IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.00039776s
[INFO] 10.244.1.163:53013 - 28987 "A IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.000218075s
[INFO] 10.244.1.163:59047 - 21227 "AAAA IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 68 0.172909835s
[INFO] 10.244.1.163:47240 - 40890 "A IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 56 0.130761222s
[INFO] 10.244.1.163:50014 - 62094 "A IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.014385479s
[INFO] 10.244.1.163:35065 - 40084 "AAAA IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.011559339s
[INFO] 10.244.1.163:45906 - 7456 "AAAA IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.000429274s
[INFO] 10.244.1.163:48293 - 11182 "A IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.002967245s
[INFO] 10.244.1.163:57852 - 30323 "AAAA IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.002413997s
[INFO] 10.244.1.163:42842 - 38166 "A IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000327618s
[INFO] 10.244.1.163:37192 - 18181 "A IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 207 0.014801599s
[INFO] 10.244.1.163:47012 - 31796 "AAAA IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 255 0.01125193s
[INFO] 10.244.1.163:39266 - 42453 "AAAA IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.000347149s
[INFO] 10.244.1.163:36329 - 59422 "A IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.000412707s
[INFO] 10.244.1.163:58742 - 47445 "AAAA IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.000206355s
[INFO] 10.244.1.163:47091 - 30020 "A IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.000374429s
[INFO] 10.244.1.163:54540 - 29125 "AAAA IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.000388851s
[INFO] 10.244.1.163:43836 - 61619 "A IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.000322824s
[INFO] 10.244.1.163:44479 - 15617 "AAAA IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 68 0.020017927s
[INFO] 10.244.1.163:49118 - 44846 "A IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 56 0.021145157s
[INFO] 10.244.1.163:37847 - 57925 "A IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.093985739s
[INFO] 10.244.1.163:43954 - 1783 "AAAA IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.09400154s
[INFO] 10.244.1.163:44661 - 52984 "AAAA IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.093939867s
[INFO] 10.244.1.163:53930 - 52008 "A IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.093854192s
[INFO] 10.244.1.163:34008 - 64525 "AAAA IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.002864798s
[INFO] 10.244.1.163:43846 - 7132 "A IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.003843777s
[INFO] 10.244.1.163:54635 - 5442 "A IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.003429596s
[INFO] 10.244.1.163:50548 - 30965 "AAAA IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.000165549s
[INFO] 10.244.1.163:59438 - 11159 "AAAA IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.00020838s
[INFO] 10.244.1.163:43071 - 4554 "A IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.000256493s
[INFO] 10.244.1.163:50455 - 57277 "A IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000966801s
[INFO] 10.244.1.163:46469 - 55821 "AAAA IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000148123s
[INFO] 10.244.1.163:48851 - 38533 "A IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 207 0.031338336s
[INFO] 10.244.1.163:39101 - 43200 "A IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 56 0.042626802s
[INFO] 10.244.1.163:59899 - 33631 "AAAA IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 255 0.035515444s
[INFO] 10.244.1.163:50443 - 45300 "AAAA IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 68 0.053811588s

* 
* ==> coredns [6ba2f8f31113] <==
* [INFO] 10.244.0.17:37885 - 58323 "AAAA IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000396831s
[INFO] 10.244.0.17:39382 - 62713 "A IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000250528s
[INFO] 10.244.0.17:39726 - 1701 "A IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 207 0.016435708s
[INFO] 10.244.0.17:33671 - 10337 "AAAA IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 255 0.015555147s
[INFO] 10.244.0.17:48170 - 51650 "A IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.000258555s
[INFO] 10.244.0.17:42718 - 24158 "AAAA IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.002741562s
[INFO] 10.244.0.17:35140 - 13554 "A IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.000194102s
[INFO] 10.244.0.17:58913 - 21634 "AAAA IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.00010819s
[INFO] 10.244.0.17:48820 - 60065 "AAAA IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.00011777s
[INFO] 10.244.0.17:42963 - 15504 "A IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.000110524s
[INFO] 10.244.0.17:48991 - 11312 "A IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 56 0.023441217s
[INFO] 10.244.0.17:36510 - 1037 "AAAA IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 68 0.026246484s
[INFO] 10.244.0.17:49478 - 8081 "AAAA IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.000312889s
[INFO] 10.244.0.17:52596 - 42578 "A IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.00352901s
[INFO] 10.244.0.17:57175 - 11601 "AAAA IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.000477912s
[INFO] 10.244.0.17:42430 - 37928 "A IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.002574283s
[INFO] 10.244.0.17:54568 - 52378 "AAAA IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000397749s
[INFO] 10.244.0.17:47574 - 13553 "A IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000166784s
[INFO] 10.244.0.17:41984 - 28013 "AAAA IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 255 0.007269985s
[INFO] 10.244.0.17:46253 - 39371 "A IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 207 0.052634626s
[INFO] 10.244.0.17:58600 - 40888 "AAAA IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.000254121s
[INFO] 10.244.0.17:53719 - 53565 "A IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.000416872s
[INFO] 10.244.0.17:59191 - 53171 "AAAA IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.001405685s
[INFO] 10.244.0.17:46533 - 35615 "A IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.000597656s
[INFO] 10.244.0.17:39827 - 24607 "AAAA IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.000213586s
[INFO] 10.244.0.17:55892 - 64745 "A IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.000201106s
[INFO] 10.244.0.17:58214 - 40716 "AAAA IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 68 0.019249267s
[INFO] 10.244.0.17:37710 - 54293 "A IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 56 0.043449223s
[INFO] 10.244.0.17:56095 - 8307 "AAAA IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.000525091s
[INFO] 10.244.0.17:36798 - 50352 "A IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.001377567s
[INFO] 10.244.0.17:57411 - 23858 "A IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.000243254s
[INFO] 10.244.0.17:42624 - 63260 "AAAA IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.000154795s
[INFO] 10.244.0.17:47669 - 64625 "A IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.001015254s
[INFO] 10.244.0.17:33399 - 47061 "AAAA IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000187509s
[INFO] 10.244.0.17:35446 - 41370 "A IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000170759s
[INFO] 10.244.0.17:33691 - 13350 "AAAA IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.000213022s
[INFO] 10.244.0.17:60511 - 2899 "AAAA IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.000155715s
[INFO] 10.244.0.17:59463 - 44812 "A IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.000321316s
[INFO] 10.244.0.17:38365 - 7540 "A IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 207 0.04868645s
[INFO] 10.244.0.17:58210 - 25996 "AAAA IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 255 0.051546143s
[INFO] 10.244.0.17:56315 - 53650 "AAAA IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.00026787s
[INFO] 10.244.0.17:57471 - 65144 "A IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.000394565s
[INFO] 10.244.0.17:40256 - 54725 "A IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 56 0.03694526s
[INFO] 10.244.0.17:51942 - 38705 "AAAA IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 68 0.070009686s
[INFO] 10.244.0.17:59061 - 38321 "A IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.001177054s
[INFO] 10.244.0.17:60431 - 1499 "AAAA IN raw.githubusercontent.com.monitoring.svc.cluster.local. udp 83 false 1232" NXDOMAIN qr,aa,rd 165 0.000262337s
[INFO] 10.244.0.17:40465 - 37545 "A IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.000199203s
[INFO] 10.244.0.17:56588 - 28058 "AAAA IN raw.githubusercontent.com.svc.cluster.local. udp 72 false 1232" NXDOMAIN qr,aa,rd 154 0.002368576s
[INFO] 10.244.0.17:38292 - 47617 "AAAA IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000726835s
[INFO] 10.244.0.17:40079 - 29208 "A IN raw.githubusercontent.com.cluster.local. udp 68 false 1232" NXDOMAIN qr,aa,rd 150 0.000193152s
[INFO] 10.244.0.17:55583 - 22931 "A IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 207 0.00898895s
[INFO] 10.244.0.17:47206 - 26058 "AAAA IN raw.githubusercontent.com. udp 54 false 1232" NOERROR qr,rd,ra 255 0.009675456s
[INFO] 10.244.0.17:36107 - 48271 "A IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.000521457s
[INFO] 10.244.0.17:55274 - 19202 "AAAA IN grafana.com.monitoring.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.000276401s
[INFO] 10.244.0.17:50160 - 41244 "A IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.000201643s
[INFO] 10.244.0.17:40567 - 35515 "AAAA IN grafana.com.svc.cluster.local. udp 58 false 1232" NXDOMAIN qr,aa,rd 140 0.00067075s
[INFO] 10.244.0.17:37988 - 58912 "AAAA IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.000267444s
[INFO] 10.244.0.17:46064 - 2228 "A IN grafana.com.cluster.local. udp 54 false 1232" NXDOMAIN qr,aa,rd 136 0.000187484s
[INFO] 10.244.0.17:51670 - 252 "AAAA IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 68 0.040534772s
[INFO] 10.244.0.17:42961 - 56952 "A IN grafana.com. udp 40 false 1232" NOERROR qr,rd,ra 56 0.042890905s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=8220a6eb95f0a4d75f7f2d7b14cef975f050512d
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2024_02_07T13_00_46_0700
                    minikube.k8s.io/version=v1.32.0
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Wed, 07 Feb 2024 05:00:42 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Mon, 12 Feb 2024 03:00:23 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Mon, 12 Feb 2024 02:56:18 +0000   Sat, 10 Feb 2024 07:41:07 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Mon, 12 Feb 2024 02:56:18 +0000   Sat, 10 Feb 2024 07:41:07 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Mon, 12 Feb 2024 02:56:18 +0000   Sat, 10 Feb 2024 07:41:07 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Mon, 12 Feb 2024 02:56:18 +0000   Sat, 10 Feb 2024 09:44:35 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                4
  ephemeral-storage:  61202244Ki
  hugepages-2Mi:      0
  memory:             4011296Ki
  pods:               110
Allocatable:
  cpu:                4
  ephemeral-storage:  61202244Ki
  hugepages-2Mi:      0
  memory:             4011296Ki
  pods:               110
System Info:
  Machine ID:                 03c421553df2475db8856ae08de1dcd9
  System UUID:                03c421553df2475db8856ae08de1dcd9
  Boot ID:                    7eb0ea73-97a5-41ed-90fb-8d6d878dd8a1
  Kernel Version:             6.6.12-linuxkit
  OS Image:                   Ubuntu 22.04.3 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://24.0.7
  Kubelet Version:            v1.28.3
  Kube-Proxy Version:         v1.28.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (15 in total)
  Namespace                   Name                                                      CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                                      ------------  ----------  ---------------  -------------  ---
  default                     mysql-d6f56dd44-w9z58                                     0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         20m
  default                     prometheus-operator-7d5c68dc4-jblgp                       100m (2%!)(MISSING)     200m (5%!)(MISSING)   100Mi (2%!)(MISSING)       200Mi (5%!)(MISSING)     44h
  kube-system                 coredns-5dd5756b68-jdzlt                                  100m (2%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     4d21h
  kube-system                 etcd-minikube                                             100m (2%!)(MISSING)     0 (0%!)(MISSING)      100Mi (2%!)(MISSING)       0 (0%!)(MISSING)         4d21h
  kube-system                 kube-apiserver-minikube                                   250m (6%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         4d21h
  kube-system                 kube-controller-manager-minikube                          200m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         4d21h
  kube-system                 kube-proxy-mc9jh                                          0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         4d21h
  kube-system                 kube-scheduler-minikube                                   100m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         4d21h
  kube-system                 storage-provisioner                                       0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         4d21h
  monitoring                  alertmanager-stable-kube-prometheus-sta-alertmanager-0    10m (0%!)(MISSING)      10m (0%!)(MISSING)    250Mi (6%!)(MISSING)       50Mi (1%!)(MISSING)      41s
  monitoring                  prometheus-stable-kube-prometheus-sta-prometheus-0        10m (0%!)(MISSING)      10m (0%!)(MISSING)    50Mi (1%!)(MISSING)        50Mi (1%!)(MISSING)      17s
  monitoring                  stable-grafana-6889bcb489-mgndv                           0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         42h
  monitoring                  stable-kube-prometheus-sta-operator-c548659cd-zt6rn       0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         42h
  monitoring                  stable-kube-state-metrics-7fdbdb97cb-kvbmr                0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         42h
  monitoring                  stable-prometheus-node-exporter-n8v48                     0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         42h
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests     Limits
  --------           --------     ------
  cpu                870m (21%!)(MISSING)   220m (5%!)(MISSING)
  memory             570Mi (14%!)(MISSING)  470Mi (11%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)       0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)       0 (0%!)(MISSING)
Events:
  Type    Reason                   Age                From             Message
  ----    ------                   ----               ----             -------
  Normal  Starting                 44m                kube-proxy       
  Normal  NodeNotReady             41h (x3 over 43h)  kubelet          Node minikube status is now: NodeNotReady
  Normal  NodeReady                41h (x4 over 44h)  kubelet          Node minikube status is now: NodeReady
  Normal  Starting                 45m                kubelet          Starting kubelet.
  Normal  NodeHasSufficientMemory  45m (x8 over 45m)  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    45m (x8 over 45m)  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     45m (x7 over 45m)  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  NodeAllocatableEnforced  45m                kubelet          Updated Node Allocatable limit across pods
  Normal  RegisteredNode           44m                node-controller  Node minikube event: Registered Node minikube in Controller

* 
* ==> dmesg <==
* 
* 
* ==> etcd [6481fa418865] <==
* {"level":"info","ts":"2024-02-12T02:59:47.282421Z","caller":"traceutil/trace.go:171","msg":"trace[612638323] range","detail":"{range_begin:/registry/configmaps/monitoring/; range_end:/registry/configmaps/monitoring0; response_count:32; response_revision:90482; }","duration":"270.877943ms","start":"2024-02-12T02:59:47.011468Z","end":"2024-02-12T02:59:47.282345Z","steps":["trace[612638323] 'range keys from bolt db'  (duration: 270.638308ms)"],"step_count":1}
{"level":"info","ts":"2024-02-12T02:59:54.187867Z","caller":"traceutil/trace.go:171","msg":"trace[119598658] transaction","detail":"{read_only:false; response_revision:90604; number_of_response:1; }","duration":"103.73768ms","start":"2024-02-12T02:59:54.084107Z","end":"2024-02-12T02:59:54.187845Z","steps":["trace[119598658] 'process raft request'  (duration: 79.659098ms)","trace[119598658] 'compare'  (duration: 23.684092ms)"],"step_count":2}
{"level":"warn","ts":"2024-02-12T02:59:54.497097Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"107.984289ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" ","response":"range_response_count:32 size:734992"}
{"level":"info","ts":"2024-02-12T02:59:54.497256Z","caller":"traceutil/trace.go:171","msg":"trace[306859138] range","detail":"{range_begin:/registry/configmaps/monitoring/; range_end:/registry/configmaps/monitoring0; response_count:32; response_revision:90609; }","duration":"108.156147ms","start":"2024-02-12T02:59:54.389076Z","end":"2024-02-12T02:59:54.497233Z","steps":["trace[306859138] 'agreement among raft nodes before linearized reading'  (duration: 92.834388ms)","trace[306859138] 'range keys from bolt db'  (duration: 15.101453ms)"],"step_count":2}
{"level":"info","ts":"2024-02-12T02:59:54.721439Z","caller":"traceutil/trace.go:171","msg":"trace[462992650] linearizableReadLoop","detail":"{readStateIndex:103503; appliedIndex:103502; }","duration":"118.364325ms","start":"2024-02-12T02:59:54.603056Z","end":"2024-02-12T02:59:54.72142Z","steps":["trace[462992650] 'read index received'  (duration: 75.856115ms)","trace[462992650] 'applied index is now lower than readState.Index'  (duration: 42.507551ms)"],"step_count":2}
{"level":"info","ts":"2024-02-12T02:59:54.72184Z","caller":"traceutil/trace.go:171","msg":"trace[902674650] transaction","detail":"{read_only:false; number_of_response:1; response_revision:90609; }","duration":"129.856719ms","start":"2024-02-12T02:59:54.591958Z","end":"2024-02-12T02:59:54.721815Z","steps":["trace[902674650] 'process raft request'  (duration: 86.908406ms)","trace[902674650] 'compare'  (duration: 42.510718ms)"],"step_count":2}
{"level":"warn","ts":"2024-02-12T02:59:54.722194Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"118.926534ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/secrets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-generated\" ","response":"range_response_count:1 size:1024"}
{"level":"info","ts":"2024-02-12T02:59:54.723316Z","caller":"traceutil/trace.go:171","msg":"trace[905556832] range","detail":"{range_begin:/registry/secrets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-generated; range_end:; response_count:1; response_revision:90609; }","duration":"120.272628ms","start":"2024-02-12T02:59:54.603014Z","end":"2024-02-12T02:59:54.723287Z","steps":["trace[905556832] 'agreement among raft nodes before linearized reading'  (duration: 118.868474ms)"],"step_count":1}
{"level":"info","ts":"2024-02-12T02:59:55.718161Z","caller":"traceutil/trace.go:171","msg":"trace[429718230] transaction","detail":"{read_only:false; response_revision:90617; number_of_response:1; }","duration":"195.989158ms","start":"2024-02-12T02:59:55.52215Z","end":"2024-02-12T02:59:55.718139Z","steps":["trace[429718230] 'process raft request'  (duration: 195.83778ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:06.700956Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"177.745888ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/secrets/\" range_end:\"/registry/secrets0\" ","response":"range_response_count:12 size:420492"}
{"level":"info","ts":"2024-02-12T03:00:06.701133Z","caller":"traceutil/trace.go:171","msg":"trace[1361649882] range","detail":"{range_begin:/registry/secrets/; range_end:/registry/secrets0; response_count:12; response_revision:90740; }","duration":"177.958112ms","start":"2024-02-12T03:00:06.523151Z","end":"2024-02-12T03:00:06.701109Z","steps":["trace[1361649882] 'range keys from bolt db'  (duration: 177.508568ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:11.394878Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"188.807559ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" ","response":"range_response_count:32 size:734992"}
{"level":"info","ts":"2024-02-12T03:00:11.39513Z","caller":"traceutil/trace.go:171","msg":"trace[1869378664] range","detail":"{range_begin:/registry/configmaps/monitoring/; range_end:/registry/configmaps/monitoring0; response_count:32; response_revision:90774; }","duration":"189.076903ms","start":"2024-02-12T03:00:11.206018Z","end":"2024-02-12T03:00:11.395095Z","steps":["trace[1869378664] 'agreement among raft nodes before linearized reading'  (duration: 16.450623ms)","trace[1869378664] 'range keys from bolt db'  (duration: 171.936256ms)"],"step_count":2}
{"level":"warn","ts":"2024-02-12T03:00:16.305051Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"226.31147ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" ","response":"range_response_count:32 size:734992"}
{"level":"info","ts":"2024-02-12T03:00:16.309171Z","caller":"traceutil/trace.go:171","msg":"trace[330047772] range","detail":"{range_begin:/registry/configmaps/monitoring/; range_end:/registry/configmaps/monitoring0; response_count:32; response_revision:90814; }","duration":"229.950566ms","start":"2024-02-12T03:00:16.078697Z","end":"2024-02-12T03:00:16.308647Z","steps":["trace[330047772] 'range keys from bolt db'  (duration: 226.105074ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:18.768963Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"106.14492ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/monitoring/\" range_end:\"/registry/pods/monitoring0\" ","response":"range_response_count:6 size:50685"}
{"level":"info","ts":"2024-02-12T03:00:18.769114Z","caller":"traceutil/trace.go:171","msg":"trace[1379882395] range","detail":"{range_begin:/registry/pods/monitoring/; range_end:/registry/pods/monitoring0; response_count:6; response_revision:90852; }","duration":"106.32239ms","start":"2024-02-12T03:00:18.662771Z","end":"2024-02-12T03:00:18.769093Z","steps":["trace[1379882395] 'range keys from bolt db'  (duration: 105.952788ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:18.772816Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"165.314872ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/monitoring/\" range_end:\"/registry/pods/monitoring0\" ","response":"range_response_count:6 size:50685"}
{"level":"info","ts":"2024-02-12T03:00:18.776034Z","caller":"traceutil/trace.go:171","msg":"trace[1877644998] range","detail":"{range_begin:/registry/pods/monitoring/; range_end:/registry/pods/monitoring0; response_count:6; response_revision:90852; }","duration":"168.546953ms","start":"2024-02-12T03:00:18.607465Z","end":"2024-02-12T03:00:18.776012Z","steps":["trace[1877644998] 'range keys from bolt db'  (duration: 164.318853ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:20.514103Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"304.272331ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" ","response":"range_response_count:32 size:734992"}
{"level":"info","ts":"2024-02-12T03:00:20.514198Z","caller":"traceutil/trace.go:171","msg":"trace[604201917] range","detail":"{range_begin:/registry/configmaps/monitoring/; range_end:/registry/configmaps/monitoring0; response_count:32; response_revision:90860; }","duration":"304.395318ms","start":"2024-02-12T03:00:20.209783Z","end":"2024-02-12T03:00:20.514178Z","steps":["trace[604201917] 'range keys from bolt db'  (duration: 304.109692ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:20.514791Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"227.906351ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" ","response":"range_response_count:32 size:734992"}
{"level":"info","ts":"2024-02-12T03:00:20.514863Z","caller":"traceutil/trace.go:171","msg":"trace[188356154] range","detail":"{range_begin:/registry/configmaps/monitoring/; range_end:/registry/configmaps/monitoring0; response_count:32; response_revision:90860; }","duration":"227.985413ms","start":"2024-02-12T03:00:20.286861Z","end":"2024-02-12T03:00:20.514847Z","steps":["trace[188356154] 'range keys from bolt db'  (duration: 227.705047ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:20.514251Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-12T03:00:20.209764Z","time spent":"304.471977ms","remote":"127.0.0.1:35638","response type":"/etcdserverpb.KV/Range","request count":0,"request size":68,"response count":32,"response size":735016,"request content":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" "}
{"level":"warn","ts":"2024-02-12T03:00:24.113465Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"147.583988ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" ","response":"range_response_count:32 size:734992"}
{"level":"info","ts":"2024-02-12T03:00:24.113603Z","caller":"traceutil/trace.go:171","msg":"trace[445144636] range","detail":"{range_begin:/registry/configmaps/monitoring/; range_end:/registry/configmaps/monitoring0; response_count:32; response_revision:90896; }","duration":"147.752089ms","start":"2024-02-12T03:00:23.965835Z","end":"2024-02-12T03:00:24.113587Z","steps":["trace[445144636] 'range keys from bolt db'  (duration: 147.304142ms)"],"step_count":1}
{"level":"info","ts":"2024-02-12T03:00:25.563566Z","caller":"traceutil/trace.go:171","msg":"trace[409751713] transaction","detail":"{read_only:false; response_revision:90908; number_of_response:1; }","duration":"101.033879ms","start":"2024-02-12T03:00:25.411061Z","end":"2024-02-12T03:00:25.512095Z","steps":["trace[409751713] 'process raft request'  (duration: 85.751603ms)","trace[409751713] 'compare'  (duration: 14.829904ms)"],"step_count":2}
{"level":"info","ts":"2024-02-12T03:00:25.903938Z","caller":"traceutil/trace.go:171","msg":"trace[1407838973] transaction","detail":"{read_only:false; response_revision:90911; number_of_response:1; }","duration":"104.638841ms","start":"2024-02-12T03:00:25.799266Z","end":"2024-02-12T03:00:25.903905Z","steps":["trace[1407838973] 'process raft request'  (duration: 67.069737ms)","trace[1407838973] 'compare'  (duration: 32.938352ms)"],"step_count":2}
{"level":"warn","ts":"2024-02-12T03:00:26.707057Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.205306931s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/\" range_end:\"/registry/events0\" limit:500 ","response":"range_response_count:500 size:423839"}
{"level":"info","ts":"2024-02-12T03:00:26.709524Z","caller":"traceutil/trace.go:171","msg":"trace[1983329033] range","detail":"{range_begin:/registry/events/; range_end:/registry/events0; response_count:500; response_revision:90908; }","duration":"1.216615783s","start":"2024-02-12T03:00:25.490512Z","end":"2024-02-12T03:00:26.707128Z","steps":["trace[1983329033] 'agreement among raft nodes before linearized reading'  (duration: 24.465447ms)","trace[1983329033] 'range keys from bolt db'  (duration: 1.178817795s)"],"step_count":2}
{"level":"warn","ts":"2024-02-12T03:00:26.70966Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-12T03:00:25.490488Z","time spent":"1.219117787s","remote":"127.0.0.1:35610","response type":"/etcdserverpb.KV/Range","request count":0,"request size":41,"response count":3794,"response size":423863,"request content":"key:\"/registry/events/\" range_end:\"/registry/events0\" limit:500 "}
{"level":"warn","ts":"2024-02-12T03:00:27.684676Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"168.729024ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" ","response":"range_response_count:32 size:734992"}
{"level":"info","ts":"2024-02-12T03:00:27.684758Z","caller":"traceutil/trace.go:171","msg":"trace[2101896621] range","detail":"{range_begin:/registry/configmaps/monitoring/; range_end:/registry/configmaps/monitoring0; response_count:32; response_revision:90927; }","duration":"168.827834ms","start":"2024-02-12T03:00:27.515911Z","end":"2024-02-12T03:00:27.684739Z","steps":["trace[2101896621] 'range keys from bolt db'  (duration: 164.229431ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:27.704699Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"884.149174ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b2fc041bbec46d\\000\" range_end:\"/registry/events0\" limit:1000 revision:90908 ","response":"range_response_count:1000 size:865831"}
{"level":"info","ts":"2024-02-12T03:00:27.704835Z","caller":"traceutil/trace.go:171","msg":"trace[1642053544] range","detail":"{range_begin:/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b2fc041bbec46d\u0000; range_end:/registry/events0; response_count:1000; response_revision:90916; }","duration":"884.298423ms","start":"2024-02-12T03:00:26.820496Z","end":"2024-02-12T03:00:27.704795Z","steps":["trace[1642053544] 'range keys from in-memory index tree'  (duration: 42.375135ms)","trace[1642053544] 'range keys from bolt db'  (duration: 841.608151ms)"],"step_count":2}
{"level":"warn","ts":"2024-02-12T03:00:27.704961Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-12T03:00:26.820483Z","time spent":"884.429011ms","remote":"127.0.0.1:35610","response type":"/etcdserverpb.KV/Range","request count":0,"request size":128,"response count":3294,"response size":865855,"request content":"key:\"/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b2fc041bbec46d\\000\" range_end:\"/registry/events0\" limit:1000 revision:90908 "}
{"level":"warn","ts":"2024-02-12T03:00:29.076694Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"104.530742ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/monitoring/\" range_end:\"/registry/pods/monitoring0\" ","response":"range_response_count:6 size:51005"}
{"level":"info","ts":"2024-02-12T03:00:29.076813Z","caller":"traceutil/trace.go:171","msg":"trace[1191822791] range","detail":"{range_begin:/registry/pods/monitoring/; range_end:/registry/pods/monitoring0; response_count:6; response_revision:90943; }","duration":"104.671046ms","start":"2024-02-12T03:00:28.972121Z","end":"2024-02-12T03:00:29.076792Z","steps":["trace[1191822791] 'range keys from in-memory index tree'  (duration: 20.865063ms)","trace[1191822791] 'range keys from bolt db'  (duration: 69.507252ms)"],"step_count":2}
{"level":"warn","ts":"2024-02-12T03:00:29.69462Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.627247734s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b2fdc9c368b57d\\000\" range_end:\"/registry/events0\" limit:2000 revision:90908 ","response":"range_response_count:2000 size:1697489"}
{"level":"info","ts":"2024-02-12T03:00:29.694684Z","caller":"traceutil/trace.go:171","msg":"trace[222372609] range","detail":"{range_begin:/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b2fdc9c368b57d\u0000; range_end:/registry/events0; response_count:2000; response_revision:90929; }","duration":"1.627344446s","start":"2024-02-12T03:00:28.067327Z","end":"2024-02-12T03:00:29.694672Z","steps":["trace[222372609] 'range keys from bolt db'  (duration: 1.619949221s)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:29.694756Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-12T03:00:28.067313Z","time spent":"1.627398392s","remote":"127.0.0.1:35610","response type":"/etcdserverpb.KV/Range","request count":0,"request size":128,"response count":2294,"response size":1697513,"request content":"key:\"/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b2fdc9c368b57d\\000\" range_end:\"/registry/events0\" limit:2000 revision:90908 "}
{"level":"warn","ts":"2024-02-12T03:00:30.386348Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"499.348001ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0.17b2fda73a68eefc\\000\" range_end:\"/registry/events0\" limit:4000 revision:90908 ","response":"range_response_count:294 size:249645"}
{"level":"info","ts":"2024-02-12T03:00:30.386798Z","caller":"traceutil/trace.go:171","msg":"trace[1300955981] range","detail":"{range_begin:/registry/events/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0.17b2fda73a68eefc\u0000; range_end:/registry/events0; response_count:294; response_revision:90950; }","duration":"501.056763ms","start":"2024-02-12T03:00:29.88571Z","end":"2024-02-12T03:00:30.386767Z","steps":["trace[1300955981] 'range keys from bolt db'  (duration: 498.807392ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:30.386911Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-12T03:00:29.885681Z","time spent":"501.179946ms","remote":"127.0.0.1:35610","response type":"/etcdserverpb.KV/Range","request count":0,"request size":124,"response count":294,"response size":249669,"request content":"key:\"/registry/events/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0.17b2fda73a68eefc\\000\" range_end:\"/registry/events0\" limit:4000 revision:90908 "}
{"level":"warn","ts":"2024-02-12T03:00:30.818647Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"110.865414ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" ","response":"range_response_count:32 size:734992"}
{"level":"info","ts":"2024-02-12T03:00:30.818806Z","caller":"traceutil/trace.go:171","msg":"trace[1558651404] range","detail":"{range_begin:/registry/configmaps/monitoring/; range_end:/registry/configmaps/monitoring0; response_count:32; response_revision:90959; }","duration":"111.115436ms","start":"2024-02-12T03:00:30.707669Z","end":"2024-02-12T03:00:30.818785Z","steps":["trace[1558651404] 'range keys from bolt db'  (duration: 105.805327ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:30.887073Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"308.611131ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/\" range_end:\"/registry/events0\" limit:500 ","response":"range_response_count:500 size:423839"}
{"level":"info","ts":"2024-02-12T03:00:30.88716Z","caller":"traceutil/trace.go:171","msg":"trace[1292884020] range","detail":"{range_begin:/registry/events/; range_end:/registry/events0; response_count:500; response_revision:90957; }","duration":"308.763251ms","start":"2024-02-12T03:00:30.578375Z","end":"2024-02-12T03:00:30.887139Z","steps":["trace[1292884020] 'agreement among raft nodes before linearized reading'  (duration: 15.153653ms)","trace[1292884020] 'range keys from in-memory index tree'  (duration: 14.483487ms)","trace[1292884020] 'range keys from bolt db'  (duration: 278.906338ms)"],"step_count":3}
{"level":"warn","ts":"2024-02-12T03:00:30.887223Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-12T03:00:30.578359Z","time spent":"308.836424ms","remote":"127.0.0.1:35610","response type":"/etcdserverpb.KV/Range","request count":0,"request size":41,"response count":3796,"response size":423863,"request content":"key:\"/registry/events/\" range_end:\"/registry/events0\" limit:500 "}
{"level":"warn","ts":"2024-02-12T03:00:31.531336Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"616.968135ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b2fc041bbec46d\\000\" range_end:\"/registry/events0\" limit:1000 revision:90957 ","response":"range_response_count:1000 size:865831"}
{"level":"info","ts":"2024-02-12T03:00:31.531488Z","caller":"traceutil/trace.go:171","msg":"trace[290439818] range","detail":"{range_begin:/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b2fc041bbec46d\u0000; range_end:/registry/events0; response_count:1000; response_revision:90961; }","duration":"617.166822ms","start":"2024-02-12T03:00:30.914308Z","end":"2024-02-12T03:00:31.531474Z","steps":["trace[290439818] 'range keys from bolt db'  (duration: 613.688876ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:31.531553Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-12T03:00:30.914291Z","time spent":"617.227291ms","remote":"127.0.0.1:35610","response type":"/etcdserverpb.KV/Range","request count":0,"request size":128,"response count":3296,"response size":865855,"request content":"key:\"/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b2fc041bbec46d\\000\" range_end:\"/registry/events0\" limit:1000 revision:90957 "}
{"level":"warn","ts":"2024-02-12T03:00:32.666352Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.056758653s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b2fdc9c368b57d\\000\" range_end:\"/registry/events0\" limit:2000 revision:90957 ","response":"range_response_count:2000 size:1697489"}
{"level":"info","ts":"2024-02-12T03:00:32.666441Z","caller":"traceutil/trace.go:171","msg":"trace[1719881501] range","detail":"{range_begin:/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b2fdc9c368b57d\u0000; range_end:/registry/events0; response_count:2000; response_revision:90970; }","duration":"1.056878608s","start":"2024-02-12T03:00:31.609541Z","end":"2024-02-12T03:00:32.666419Z","steps":["trace[1719881501] 'range keys from bolt db'  (duration: 1.05267078s)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:32.666558Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-12T03:00:31.609524Z","time spent":"1.056957559s","remote":"127.0.0.1:35610","response type":"/etcdserverpb.KV/Range","request count":0,"request size":128,"response count":2296,"response size":1697513,"request content":"key:\"/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b2fdc9c368b57d\\000\" range_end:\"/registry/events0\" limit:2000 revision:90957 "}
{"level":"warn","ts":"2024-02-12T03:00:33.52627Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"190.938378ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" ","response":"range_response_count:32 size:734992"}
{"level":"info","ts":"2024-02-12T03:00:33.526377Z","caller":"traceutil/trace.go:171","msg":"trace[280285507] range","detail":"{range_begin:/registry/configmaps/monitoring/; range_end:/registry/configmaps/monitoring0; response_count:32; response_revision:90998; }","duration":"191.074838ms","start":"2024-02-12T03:00:33.335277Z","end":"2024-02-12T03:00:33.526352Z","steps":["trace[280285507] 'range keys from bolt db'  (duration: 190.772019ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:33.817834Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"912.48719ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0.17b2fda73a68eefc\\000\" range_end:\"/registry/events0\" limit:4000 revision:90957 ","response":"range_response_count:296 size:251326"}
{"level":"info","ts":"2024-02-12T03:00:33.817925Z","caller":"traceutil/trace.go:171","msg":"trace[80306828] range","detail":"{range_begin:/registry/events/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0.17b2fda73a68eefc\u0000; range_end:/registry/events0; response_count:296; response_revision:90991; }","duration":"912.615279ms","start":"2024-02-12T03:00:32.905292Z","end":"2024-02-12T03:00:33.817908Z","steps":["trace[80306828] 'range keys from bolt db'  (duration: 912.102044ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-12T03:00:33.818002Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-12T03:00:32.905273Z","time spent":"912.689636ms","remote":"127.0.0.1:35610","response type":"/etcdserverpb.KV/Range","request count":0,"request size":124,"response count":296,"response size":251350,"request content":"key:\"/registry/events/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0.17b2fda73a68eefc\\000\" range_end:\"/registry/events0\" limit:4000 revision:90957 "}

* 
* ==> etcd [95b00de29d3d] <==
* {"level":"warn","ts":"2024-02-10T09:49:26.664889Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-10T09:49:25.981511Z","time spent":"683.336281ms","remote":"127.0.0.1:60428","response type":"/etcdserverpb.KV/Range","request count":0,"request size":92,"response count":0,"response size":30,"request content":"key:\"/registry/secrets/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-tls-assets-1\" "}
{"level":"info","ts":"2024-02-10T09:49:26.665245Z","caller":"traceutil/trace.go:171","msg":"trace[1357508043] transaction","detail":"{read_only:false; response_revision:57654; number_of_response:1; }","duration":"277.438492ms","start":"2024-02-10T09:49:26.387786Z","end":"2024-02-10T09:49:26.665225Z","steps":["trace[1357508043] 'process raft request'  (duration: 272.79887ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:49:26.665248Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"638.099324ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/statefulsets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager\" ","response":"range_response_count:1 size:10184"}
{"level":"info","ts":"2024-02-10T09:49:26.665463Z","caller":"traceutil/trace.go:171","msg":"trace[601285714] range","detail":"{range_begin:/registry/statefulsets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager; range_end:; response_count:1; response_revision:57654; }","duration":"638.320883ms","start":"2024-02-10T09:49:26.027126Z","end":"2024-02-10T09:49:26.665447Z","steps":["trace[601285714] 'agreement among raft nodes before linearized reading'  (duration: 638.022899ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:49:26.665515Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-10T09:49:26.027114Z","time spent":"638.380361ms","remote":"127.0.0.1:60790","response type":"/etcdserverpb.KV/Range","request count":0,"request size":88,"response count":1,"response size":10208,"request content":"key:\"/registry/statefulsets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager\" "}
{"level":"warn","ts":"2024-02-10T09:49:26.668211Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"199.548471ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" ","response":"range_response_count:1 size:1112"}
{"level":"info","ts":"2024-02-10T09:49:26.66835Z","caller":"traceutil/trace.go:171","msg":"trace[914230317] range","detail":"{range_begin:/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath; range_end:; response_count:1; response_revision:57654; }","duration":"199.690298ms","start":"2024-02-10T09:49:26.468635Z","end":"2024-02-10T09:49:26.668326Z","steps":["trace[914230317] 'agreement among raft nodes before linearized reading'  (duration: 196.641869ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:49:27.164556Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"479.094157ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128027079457910746 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:57626 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:1020 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >>","response":"size:18"}
{"level":"info","ts":"2024-02-10T09:49:27.164976Z","caller":"traceutil/trace.go:171","msg":"trace[1148464311] transaction","detail":"{read_only:false; response_revision:57655; number_of_response:1; }","duration":"482.19322ms","start":"2024-02-10T09:49:26.682754Z","end":"2024-02-10T09:49:27.164948Z","steps":["trace[1148464311] 'get key's previous created_revision and leaseID' {req_type:put; key:/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath; req_size:1090; } (duration: 477.299161ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:49:27.16525Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-10T09:49:26.682734Z","time spent":"482.325665ms","remote":"127.0.0.1:60496","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":1093,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:57626 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:1020 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >"}
{"level":"warn","ts":"2024-02-10T09:49:28.482677Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.317708571s","expected-duration":"100ms","prefix":"","request":"header:<ID:8128027079457910747 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b277781bd1b5c6\" mod_revision:0 > success:<request_put:<key:\"/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b277781bd1b5c6\" value_size:725 lease:8128027079457907191 >> failure:<>>","response":"size:18"}
{"level":"info","ts":"2024-02-10T09:49:28.483011Z","caller":"traceutil/trace.go:171","msg":"trace[1362577556] linearizableReadLoop","detail":"{readStateIndex:67663; appliedIndex:67661; }","duration":"1.79590262s","start":"2024-02-10T09:49:26.687083Z","end":"2024-02-10T09:49:28.482985Z","steps":["trace[1362577556] 'read index received'  (duration: 1.603644ms)","trace[1362577556] 'applied index is now lower than readState.Index'  (duration: 1.794297844s)"],"step_count":2}
{"level":"info","ts":"2024-02-10T09:49:28.483127Z","caller":"traceutil/trace.go:171","msg":"trace[293049815] transaction","detail":"{read_only:false; response_revision:57656; number_of_response:1; }","duration":"1.797697774s","start":"2024-02-10T09:49:26.685395Z","end":"2024-02-10T09:49:28.483092Z","steps":["trace[293049815] 'process raft request'  (duration: 479.530231ms)","trace[293049815] 'compare'  (duration: 14.94436ms)","trace[293049815] 'marshal mvccpb.KeyValue' {req_type:put; key:/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b277781bd1b5c6; req_size:839; } (duration: 1.302397312s)"],"step_count":3}
{"level":"warn","ts":"2024-02-10T09:49:28.483244Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-10T09:49:26.685373Z","time spent":"1.797804394s","remote":"127.0.0.1:60408","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":842,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b277781bd1b5c6\" mod_revision:0 > success:<request_put:<key:\"/registry/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b277781bd1b5c6\" value_size:725 lease:8128027079457907191 >> failure:<>"}
{"level":"warn","ts":"2024-02-10T09:49:28.486292Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.799218886s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/secrets/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-web-config\" ","response":"range_response_count:1 size:714"}
{"level":"info","ts":"2024-02-10T09:49:28.486387Z","caller":"traceutil/trace.go:171","msg":"trace[48804506] range","detail":"{range_begin:/registry/secrets/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-web-config; range_end:; response_count:1; response_revision:57656; }","duration":"1.799326349s","start":"2024-02-10T09:49:26.687047Z","end":"2024-02-10T09:49:28.486373Z","steps":["trace[48804506] 'agreement among raft nodes before linearized reading'  (duration: 1.796081922s)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:49:28.486423Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-10T09:49:26.68703Z","time spent":"1.799383978s","remote":"127.0.0.1:60428","response type":"/etcdserverpb.KV/Range","request count":0,"request size":90,"response count":1,"response size":738,"request content":"key:\"/registry/secrets/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-web-config\" "}
{"level":"warn","ts":"2024-02-10T09:49:28.487187Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.798250166s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/secrets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager\" ","response":"range_response_count:1 size:1794"}
{"level":"info","ts":"2024-02-10T09:49:28.487253Z","caller":"traceutil/trace.go:171","msg":"trace[1877489660] range","detail":"{range_begin:/registry/secrets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager; range_end:; response_count:1; response_revision:57657; }","duration":"1.798321268s","start":"2024-02-10T09:49:26.688914Z","end":"2024-02-10T09:49:28.487235Z","steps":["trace[1877489660] 'agreement among raft nodes before linearized reading'  (duration: 1.798214565s)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:49:28.487431Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-10T09:49:26.688898Z","time spent":"1.798513829s","remote":"127.0.0.1:60428","response type":"/etcdserverpb.KV/Range","request count":0,"request size":83,"response count":1,"response size":1818,"request content":"key:\"/registry/secrets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager\" "}
{"level":"info","ts":"2024-02-10T09:49:28.487487Z","caller":"traceutil/trace.go:171","msg":"trace[485437208] transaction","detail":"{read_only:false; response_revision:57657; number_of_response:1; }","duration":"1.643775253s","start":"2024-02-10T09:49:26.8437Z","end":"2024-02-10T09:49:28.487475Z","steps":["trace[485437208] 'process raft request'  (duration: 1.639277503s)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:49:28.487578Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-10T09:49:26.843672Z","time spent":"1.643847161s","remote":"127.0.0.1:60790","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":10489,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/statefulsets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager\" mod_revision:57653 > success:<request_put:<key:\"/registry/statefulsets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager\" value_size:10395 >> failure:<request_range:<key:\"/registry/statefulsets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager\" > >"}
{"level":"warn","ts":"2024-02-10T09:49:28.487437Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"629.649333ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0\" ","response":"range_response_count:1 size:12345"}
{"level":"info","ts":"2024-02-10T09:49:28.488269Z","caller":"traceutil/trace.go:171","msg":"trace[1708781380] range","detail":"{range_begin:/registry/pods/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0; range_end:; response_count:1; response_revision:57657; }","duration":"630.468758ms","start":"2024-02-10T09:49:27.857773Z","end":"2024-02-10T09:49:28.488242Z","steps":["trace[1708781380] 'agreement among raft nodes before linearized reading'  (duration: 629.533893ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:49:28.4887Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.153489064s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" ","response":"range_response_count:32 size:734992"}
{"level":"info","ts":"2024-02-10T09:49:28.48883Z","caller":"traceutil/trace.go:171","msg":"trace[911932670] range","detail":"{range_begin:/registry/configmaps/monitoring/; range_end:/registry/configmaps/monitoring0; response_count:32; response_revision:57657; }","duration":"1.153631922s","start":"2024-02-10T09:49:27.335178Z","end":"2024-02-10T09:49:28.48881Z","steps":["trace[911932670] 'agreement among raft nodes before linearized reading'  (duration: 1.153024125s)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:49:28.488881Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-10T09:49:27.335157Z","time spent":"1.153709019s","remote":"127.0.0.1:60432","response type":"/etcdserverpb.KV/Range","request count":0,"request size":68,"response count":32,"response size":735016,"request content":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" "}
{"level":"warn","ts":"2024-02-10T09:49:28.488969Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.777047589s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2024-02-10T09:49:28.489028Z","caller":"traceutil/trace.go:171","msg":"trace[1526515573] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:57657; }","duration":"1.777269749s","start":"2024-02-10T09:49:26.711736Z","end":"2024-02-10T09:49:28.489006Z","steps":["trace[1526515573] 'agreement among raft nodes before linearized reading'  (duration: 1.777006902s)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:49:28.489075Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-10T09:49:26.711721Z","time spent":"1.777339941s","remote":"127.0.0.1:60350","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":30,"request content":"key:\"/registry/health\" "}
{"level":"warn","ts":"2024-02-10T09:49:28.488722Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-10T09:49:27.857759Z","time spent":"630.937961ms","remote":"127.0.0.1:60504","response type":"/etcdserverpb.KV/Range","request count":0,"request size":78,"response count":1,"response size":12369,"request content":"key:\"/registry/pods/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0\" "}
{"level":"warn","ts":"2024-02-10T09:49:28.488164Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.777390139s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/monitoring.coreos.com/alertmanagers/monitoring/stable-kube-prometheus-sta-alertmanager\" ","response":"range_response_count:1 size:3388"}
{"level":"info","ts":"2024-02-10T09:49:28.489616Z","caller":"traceutil/trace.go:171","msg":"trace[1326941958] range","detail":"{range_begin:/registry/monitoring.coreos.com/alertmanagers/monitoring/stable-kube-prometheus-sta-alertmanager; range_end:; response_count:1; response_revision:57657; }","duration":"1.778843625s","start":"2024-02-10T09:49:26.710751Z","end":"2024-02-10T09:49:28.489595Z","steps":["trace[1326941958] 'agreement among raft nodes before linearized reading'  (duration: 1.777339496s)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:49:28.489691Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-10T09:49:26.710732Z","time spent":"1.778934408s","remote":"127.0.0.1:57260","response type":"/etcdserverpb.KV/Range","request count":0,"request size":98,"response count":1,"response size":3412,"request content":"key:\"/registry/monitoring.coreos.com/alertmanagers/monitoring/stable-kube-prometheus-sta-alertmanager\" "}
{"level":"info","ts":"2024-02-10T09:49:28.56403Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":52923,"took":"2.607207858s","hash":4170688477}
{"level":"info","ts":"2024-02-10T09:49:28.564142Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":4170688477,"revision":52923,"compact-revision":52213}
{"level":"info","ts":"2024-02-10T09:49:56.788551Z","caller":"traceutil/trace.go:171","msg":"trace[103910978] transaction","detail":"{read_only:false; response_revision:58124; number_of_response:1; }","duration":"112.062721ms","start":"2024-02-10T09:49:56.676461Z","end":"2024-02-10T09:49:56.788524Z","steps":["trace[103910978] 'process raft request'  (duration: 83.508932ms)","trace[103910978] 'compare'  (duration: 25.4135ms)"],"step_count":2}
{"level":"info","ts":"2024-02-10T09:49:56.79461Z","caller":"traceutil/trace.go:171","msg":"trace[223552951] linearizableReadLoop","detail":"{readStateIndex:68165; appliedIndex:68164; }","duration":"109.006095ms","start":"2024-02-10T09:49:56.685582Z","end":"2024-02-10T09:49:56.794588Z","steps":["trace[223552951] 'read index received'  (duration: 74.402497ms)","trace[223552951] 'applied index is now lower than readState.Index'  (duration: 34.600447ms)"],"step_count":2}
{"level":"warn","ts":"2024-02-10T09:49:56.867243Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"109.26382ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/resourcequotas/kube-system/\" range_end:\"/registry/resourcequotas/kube-system0\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2024-02-10T09:49:56.867326Z","caller":"traceutil/trace.go:171","msg":"trace[906353388] range","detail":"{range_begin:/registry/resourcequotas/kube-system/; range_end:/registry/resourcequotas/kube-system0; response_count:0; response_revision:58126; }","duration":"181.751847ms","start":"2024-02-10T09:49:56.685553Z","end":"2024-02-10T09:49:56.867305Z","steps":["trace[906353388] 'agreement among raft nodes before linearized reading'  (duration: 109.2307ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:49:58.480303Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"114.470184ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/monitoring/\" range_end:\"/registry/configmaps/monitoring0\" ","response":"range_response_count:32 size:734992"}
{"level":"info","ts":"2024-02-10T09:49:58.480493Z","caller":"traceutil/trace.go:171","msg":"trace[767198930] range","detail":"{range_begin:/registry/configmaps/monitoring/; range_end:/registry/configmaps/monitoring0; response_count:32; response_revision:58147; }","duration":"114.667973ms","start":"2024-02-10T09:49:58.365797Z","end":"2024-02-10T09:49:58.480465Z","steps":["trace[767198930] 'agreement among raft nodes before linearized reading'  (duration: 17.968895ms)","trace[767198930] 'range keys from bolt db'  (duration: 96.424367ms)"],"step_count":2}
{"level":"info","ts":"2024-02-10T09:50:07.782818Z","caller":"traceutil/trace.go:171","msg":"trace[217298285] transaction","detail":"{read_only:false; response_revision:58313; number_of_response:1; }","duration":"566.381621ms","start":"2024-02-10T09:50:07.216387Z","end":"2024-02-10T09:50:07.782769Z","steps":["trace[217298285] 'process raft request'  (duration: 300.942044ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:50:07.783012Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-02-10T09:50:07.216103Z","time spent":"566.833926ms","remote":"127.0.0.1:60504","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":11563,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/pods/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0\" mod_revision:58312 > success:<request_put:<key:\"/registry/pods/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0\" value_size:11475 >> failure:<request_range:<key:\"/registry/pods/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0\" > >"}
{"level":"info","ts":"2024-02-10T09:50:07.899712Z","caller":"traceutil/trace.go:171","msg":"trace[1441172365] transaction","detail":"{read_only:false; number_of_response:1; response_revision:58314; }","duration":"108.112037ms","start":"2024-02-10T09:50:07.791577Z","end":"2024-02-10T09:50:07.899689Z","steps":["trace[1441172365] 'process raft request'  (duration: 108.010553ms)"],"step_count":1}
{"level":"info","ts":"2024-02-10T09:50:07.903951Z","caller":"traceutil/trace.go:171","msg":"trace[1987306695] transaction","detail":"{read_only:false; response_revision:58314; number_of_response:1; }","duration":"113.035356ms","start":"2024-02-10T09:50:07.789626Z","end":"2024-02-10T09:50:07.902661Z","steps":["trace[1987306695] 'process raft request'  (duration: 104.888872ms)"],"step_count":1}
{"level":"info","ts":"2024-02-10T09:50:07.904481Z","caller":"traceutil/trace.go:171","msg":"trace[561809301] linearizableReadLoop","detail":"{readStateIndex:68375; appliedIndex:68374; }","duration":"112.754698ms","start":"2024-02-10T09:50:07.791705Z","end":"2024-02-10T09:50:07.90446Z","steps":["trace[561809301] 'read index received'  (duration: 102.822103ms)","trace[561809301] 'applied index is now lower than readState.Index'  (duration: 9.929839ms)"],"step_count":2}
{"level":"warn","ts":"2024-02-10T09:50:07.904724Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"113.05406ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0\" ","response":"range_response_count:1 size:11581"}
{"level":"info","ts":"2024-02-10T09:50:07.904775Z","caller":"traceutil/trace.go:171","msg":"trace[1504413503] range","detail":"{range_begin:/registry/pods/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0; range_end:; response_count:1; response_revision:58314; }","duration":"113.118749ms","start":"2024-02-10T09:50:07.791642Z","end":"2024-02-10T09:50:07.904761Z","steps":["trace[1504413503] 'agreement among raft nodes before linearized reading'  (duration: 112.944494ms)"],"step_count":1}
{"level":"info","ts":"2024-02-10T09:50:15.183247Z","caller":"traceutil/trace.go:171","msg":"trace[1492043377] linearizableReadLoop","detail":"{readStateIndex:68509; appliedIndex:68508; }","duration":"114.7382ms","start":"2024-02-10T09:50:15.068488Z","end":"2024-02-10T09:50:15.183226Z","steps":["trace[1492043377] 'read index received'  (duration: 113.099159ms)","trace[1492043377] 'applied index is now lower than readState.Index'  (duration: 1.637665ms)"],"step_count":2}
{"level":"info","ts":"2024-02-10T09:50:15.183685Z","caller":"traceutil/trace.go:171","msg":"trace[1228025199] transaction","detail":"{read_only:false; response_revision:58431; number_of_response:1; }","duration":"116.589471ms","start":"2024-02-10T09:50:15.067067Z","end":"2024-02-10T09:50:15.183657Z","steps":["trace[1228025199] 'process raft request'  (duration: 114.61274ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:50:15.183923Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"115.368009ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0\" ","response":"range_response_count:1 size:11581"}
{"level":"info","ts":"2024-02-10T09:50:15.184683Z","caller":"traceutil/trace.go:171","msg":"trace[2038213098] range","detail":"{range_begin:/registry/pods/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0; range_end:; response_count:1; response_revision:58431; }","duration":"116.203849ms","start":"2024-02-10T09:50:15.068449Z","end":"2024-02-10T09:50:15.184653Z","steps":["trace[2038213098] 'agreement among raft nodes before linearized reading'  (duration: 115.311764ms)"],"step_count":1}
{"level":"info","ts":"2024-02-10T09:50:29.450111Z","caller":"traceutil/trace.go:171","msg":"trace[153462684] transaction","detail":"{read_only:false; response_revision:58668; number_of_response:1; }","duration":"149.342838ms","start":"2024-02-10T09:50:29.300747Z","end":"2024-02-10T09:50:29.45009Z","steps":["trace[153462684] 'process raft request'  (duration: 146.236096ms)"],"step_count":1}
{"level":"info","ts":"2024-02-10T09:50:29.450107Z","caller":"traceutil/trace.go:171","msg":"trace[779079732] linearizableReadLoop","detail":"{readStateIndex:68771; appliedIndex:68770; }","duration":"148.761284ms","start":"2024-02-10T09:50:29.301319Z","end":"2024-02-10T09:50:29.45008Z","steps":["trace[779079732] 'read index received'  (duration: 145.592051ms)","trace[779079732] 'applied index is now lower than readState.Index'  (duration: 3.167253ms)"],"step_count":2}
{"level":"warn","ts":"2024-02-10T09:50:29.451519Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"150.202745ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/monitoring/\" range_end:\"/registry/pods/monitoring0\" ","response":"range_response_count:6 size:49032"}
{"level":"info","ts":"2024-02-10T09:50:29.452069Z","caller":"traceutil/trace.go:171","msg":"trace[818131732] range","detail":"{range_begin:/registry/pods/monitoring/; range_end:/registry/pods/monitoring0; response_count:6; response_revision:58668; }","duration":"150.764348ms","start":"2024-02-10T09:50:29.301284Z","end":"2024-02-10T09:50:29.452049Z","steps":["trace[818131732] 'agreement among raft nodes before linearized reading'  (duration: 148.845727ms)"],"step_count":1}
{"level":"warn","ts":"2024-02-10T09:50:29.815661Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"123.411009ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/specs/\" range_end:\"/registry/services/specs0\" ","response":"range_response_count:19 size:24309"}
{"level":"info","ts":"2024-02-10T09:50:29.815791Z","caller":"traceutil/trace.go:171","msg":"trace[2039369644] range","detail":"{range_begin:/registry/services/specs/; range_end:/registry/services/specs0; response_count:19; response_revision:58670; }","duration":"123.556813ms","start":"2024-02-10T09:50:29.692213Z","end":"2024-02-10T09:50:29.81577Z","steps":["trace[2039369644] 'range keys from bolt db'  (duration: 123.260696ms)"],"step_count":1}
{"level":"info","ts":"2024-02-10T09:50:33.360007Z","caller":"traceutil/trace.go:171","msg":"trace[2081705230] transaction","detail":"{read_only:false; response_revision:58739; number_of_response:1; }","duration":"253.324509ms","start":"2024-02-10T09:50:33.106655Z","end":"2024-02-10T09:50:33.359979Z","steps":["trace[2081705230] 'process raft request'  (duration: 248.608265ms)"],"step_count":1}

* 
* ==> kernel <==
*  03:00:36 up 47 min,  0 users,  load average: 15.50, 14.71, 15.68
Linux minikube 6.6.12-linuxkit #1 SMP PREEMPT_DYNAMIC Fri Jan 19 12:50:23 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.3 LTS"

* 
* ==> kube-apiserver [c16896f05713] <==
* Trace[1628854548]: ["GuaranteedUpdate etcd3" audit-id:83d8160f-34f1-4e0f-a110-a0f3a6eaaaf9,key:/monitoring.coreos.com/alertmanagers/monitoring/stable-kube-prometheus-sta-alertmanager,type:*unstructured.Unstructured,resource:alertmanagers.monitoring.coreos.com 686ms (02:57:31.614)
Trace[1628854548]:  ---"About to Encode" 169ms (02:57:31.783)
Trace[1628854548]:  ---"Txn call completed" 197ms (02:57:31.981)]
Trace[1628854548]: ---"About to check admission control" 93ms (02:57:31.708)
Trace[1628854548]: ---"About to apply patch" 274ms (02:57:31.982)
Trace[1628854548]: ---"Object stored in database" 314ms (02:57:32.300)
Trace[1628854548]: [687.652542ms] [687.652542ms] END
I0212 02:57:32.308950       1 trace.go:236] Trace[1268068001]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:6e594729-dbc9-4a1b-899c-631bec8b1862,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/monitoring/pods/prometheus-stable-kube-prometheus-sta-prometheus-0/status,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:PATCH (12-Feb-2024 02:57:31.797) (total time: 511ms):
Trace[1268068001]: ["GuaranteedUpdate etcd3" audit-id:6e594729-dbc9-4a1b-899c-631bec8b1862,key:/pods/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0,type:*core.Pod,resource:pods 510ms (02:57:31.798)
Trace[1268068001]:  ---"About to Encode" 273ms (02:57:32.072)
Trace[1268068001]:  ---"Txn call completed" 214ms (02:57:32.307)]
Trace[1268068001]: ---"About to check admission control" 73ms (02:57:31.871)
Trace[1268068001]: ---"Object stored in database" 436ms (02:57:32.308)
Trace[1268068001]: [511.04308ms] [511.04308ms] END
I0212 02:57:33.792606       1 trace.go:236] Trace[1896006743]: "Patch" accept:application/json, */*,audit-id:975d6827-9604-4ab3-8749-54d7b73b0bd9,client:10.244.1.164,protocol:HTTP/2.0,resource:alertmanagers,scope:resource,url:/apis/monitoring.coreos.com/v1/namespaces/monitoring/alertmanagers/stable-kube-prometheus-sta-alertmanager/status,user-agent:PrometheusOperator/0.71.2,verb:APPLY (12-Feb-2024 02:57:32.895) (total time: 897ms):
Trace[1896006743]: ["GuaranteedUpdate etcd3" audit-id:975d6827-9604-4ab3-8749-54d7b73b0bd9,key:/monitoring.coreos.com/alertmanagers/monitoring/stable-kube-prometheus-sta-alertmanager,type:*unstructured.Unstructured,resource:alertmanagers.monitoring.coreos.com 890ms (02:57:32.902)
Trace[1896006743]:  ---"Txn call completed" 530ms (02:57:33.470)
Trace[1896006743]:  ---"About to Encode" 91ms (02:57:33.563)]
Trace[1896006743]: ---"About to check admission control" 21ms (02:57:32.937)
Trace[1896006743]: ---"About to apply patch" 534ms (02:57:33.471)
Trace[1896006743]: ---"About to check admission control" 30ms (02:57:33.502)
Trace[1896006743]: ---"Object stored in database" 289ms (02:57:33.792)
Trace[1896006743]: [897.290697ms] [897.290697ms] END
I0212 02:57:33.864739       1 trace.go:236] Trace[151406555]: "Update" accept:application/json, */*,audit-id:b99e6234-99ce-4f1b-94c4-5cdfc12baed6,client:10.244.1.164,protocol:HTTP/2.0,resource:services,scope:resource,url:/api/v1/namespaces/monitoring/services/alertmanager-operated,user-agent:PrometheusOperator/0.71.2,verb:PUT (12-Feb-2024 02:57:32.763) (total time: 1101ms):
Trace[151406555]: ["GuaranteedUpdate etcd3" audit-id:b99e6234-99ce-4f1b-94c4-5cdfc12baed6,key:/services/specs/monitoring/alertmanager-operated,type:*core.Service,resource:services 1078ms (02:57:32.786)
Trace[151406555]:  ---"About to Encode" 1013ms (02:57:33.799)]
Trace[151406555]: ---"Writing http response done" 43ms (02:57:33.864)
Trace[151406555]: [1.10135689s] [1.10135689s] END
I0212 02:57:33.869605       1 trace.go:236] Trace[1075397796]: "Update" accept:application/json, */*,audit-id:4c171bdf-7e18-4e72-8b57-caa5f4976f91,client:10.244.1.162,protocol:HTTP/2.0,resource:services,scope:resource,url:/api/v1/namespaces/monitoring/services/alertmanager-operated,user-agent:PrometheusOperator/0.71.2,verb:PUT (12-Feb-2024 02:57:32.819) (total time: 1049ms):
Trace[1075397796]: ["GuaranteedUpdate etcd3" audit-id:4c171bdf-7e18-4e72-8b57-caa5f4976f91,key:/services/specs/monitoring/alertmanager-operated,type:*core.Service,resource:services 1048ms (02:57:32.821)
Trace[1075397796]:  ---"About to Encode" 978ms (02:57:33.800)]
Trace[1075397796]: ---"Writing http response done" 47ms (02:57:33.869)
Trace[1075397796]: [1.04993302s] [1.04993302s] END
I0212 02:57:34.395926       1 trace.go:236] Trace[864862083]: "List" accept:application/json, */*,audit-id:f5f70dd9-44c8-4a4b-adfd-495d4f7205e3,client:10.244.1.162,protocol:HTTP/2.0,resource:configmaps,scope:namespace,url:/api/v1/namespaces/monitoring/configmaps,user-agent:PrometheusOperator/0.71.2,verb:LIST (12-Feb-2024 02:57:33.780) (total time: 615ms):
Trace[864862083]: ---"Writing http response done" count:1 417ms (02:57:34.395)
Trace[864862083]: [615.444626ms] [615.444626ms] END
I0212 02:58:37.666808       1 trace.go:236] Trace[2031500332]: "List" accept:application/json, */*,audit-id:1ca3d096-38b6-4f9a-b57b-f9250d688375,client:10.244.1.162,protocol:HTTP/2.0,resource:configmaps,scope:namespace,url:/api/v1/namespaces/monitoring/configmaps,user-agent:PrometheusOperator/0.71.2,verb:LIST (12-Feb-2024 02:58:37.105) (total time: 558ms):
Trace[2031500332]: ---"Writing http response done" count:1 88ms (02:58:37.664)
Trace[2031500332]: [558.506584ms] [558.506584ms] END
I0212 03:00:11.899975       1 trace.go:236] Trace[579976422]: "List" accept:application/json, */*,audit-id:f590db71-f6bc-472a-9f8b-d0009725cdcd,client:10.244.1.164,protocol:HTTP/2.0,resource:configmaps,scope:namespace,url:/api/v1/namespaces/monitoring/configmaps,user-agent:PrometheusOperator/0.71.2,verb:LIST (12-Feb-2024 03:00:11.195) (total time: 690ms):
Trace[579976422]: ---"Writing http response done" count:1 311ms (03:00:11.886)
Trace[579976422]: [690.27166ms] [690.27166ms] END
I0212 03:00:18.889445       1 trace.go:236] Trace[1646141199]: "Patch" accept:application/json, */*,audit-id:b3ad101c-2586-4af5-8a23-7dce629d640b,client:10.244.1.164,protocol:HTTP/2.0,resource:alertmanagers,scope:resource,url:/apis/monitoring.coreos.com/v1/namespaces/monitoring/alertmanagers/stable-kube-prometheus-sta-alertmanager/status,user-agent:PrometheusOperator/0.71.2,verb:APPLY (12-Feb-2024 03:00:18.313) (total time: 573ms):
Trace[1646141199]: ---"limitedReadBody succeeded" len:657 54ms (03:00:18.367)
Trace[1646141199]: ---"About to check admission control" 275ms (03:00:18.669)
Trace[1646141199]: ---"About to apply patch" 38ms (03:00:18.708)
Trace[1646141199]: ---"Object stored in database" 171ms (03:00:18.883)
Trace[1646141199]: [573.442824ms] [573.442824ms] END
I0212 03:00:30.475204       1 trace.go:236] Trace[494811888]: "List" accept:application/json, */*,audit-id:1f62eeeb-291c-4a04-9cb7-ed8c67ea99cc,client:127.0.0.1,protocol:HTTP/2.0,resource:events,scope:cluster,url:/api/v1/events,user-agent:kubectl/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:LIST (12-Feb-2024 03:00:25.387) (total time: 5081ms):
Trace[494811888]: ["List(recursive=true) etcd3" audit-id:1f62eeeb-291c-4a04-9cb7-ed8c67ea99cc,key:/events,resourceVersion:,resourceVersionMatch:,limit:500,continue: 5077ms (03:00:25.392)]
Trace[494811888]: ---"Writing http response done" count:1 58ms (03:00:30.469)
Trace[494811888]: [5.081977731s] [5.081977731s] END
I0212 03:00:33.976524       1 trace.go:236] Trace[1727679335]: "List" accept:application/json, */*,audit-id:4fee2d02-37f3-4800-9496-881c4c35f04f,client:127.0.0.1,protocol:HTTP/2.0,resource:events,scope:cluster,url:/api/v1/events,user-agent:kubectl/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:LIST (12-Feb-2024 03:00:30.563) (total time: 3398ms):
Trace[1727679335]: ["List(recursive=true) etcd3" audit-id:4fee2d02-37f3-4800-9496-881c4c35f04f,key:/events,resourceVersion:,resourceVersionMatch:,limit:500,continue: 3386ms (03:00:30.576)]
Trace[1727679335]: ---"Writing http response done" count:8 54ms (03:00:33.962)
Trace[1727679335]: [3.398985381s] [3.398985381s] END
I0212 03:00:34.078892       1 trace.go:236] Trace[1982705525]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:6556a9b9-499d-4e20-8933-321c09e432ec,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/monitoring/pods/prometheus-stable-kube-prometheus-sta-prometheus-0/status,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:PATCH (12-Feb-2024 03:00:33.571) (total time: 507ms):
Trace[1982705525]: ---"About to check admission control" 428ms (03:00:34.000)
Trace[1982705525]: ---"Object stored in database" 69ms (03:00:34.070)
Trace[1982705525]: [507.415844ms] [507.415844ms] END

* 
* ==> kube-apiserver [faee097e5583] <==
* Trace[511914587]: [669.355736ms] [669.355736ms] END
I0210 09:46:46.341305       1 trace.go:236] Trace[1072294570]: "Update" accept:application/json, */*,audit-id:d9d7da5b-7fc9-4c00-b062-04c92609f8cf,client:10.244.0.14,protocol:HTTP/2.0,resource:services,scope:resource,url:/api/v1/namespaces/monitoring/services/alertmanager-operated,user-agent:PrometheusOperator/0.71.2,verb:PUT (10-Feb-2024 09:46:45.257) (total time: 993ms):
Trace[1072294570]: ["GuaranteedUpdate etcd3" audit-id:d9d7da5b-7fc9-4c00-b062-04c92609f8cf,key:/services/specs/monitoring/alertmanager-operated,type:*core.Service,resource:services 992ms (09:46:45.258)]
Trace[1072294570]: [993.331402ms] [993.331402ms] END
I0210 09:46:46.354678       1 trace.go:236] Trace[1552112191]: "Patch" accept:application/json, */*,audit-id:d3b77901-4536-46cf-a0b7-f734f8c39ff8,client:10.244.0.14,protocol:HTTP/2.0,resource:prometheuses,scope:resource,url:/apis/monitoring.coreos.com/v1/namespaces/monitoring/prometheuses/stable-kube-prometheus-sta-prometheus/status,user-agent:PrometheusOperator/0.71.2,verb:APPLY (10-Feb-2024 09:46:45.210) (total time: 1038ms):
Trace[1552112191]: ["GuaranteedUpdate etcd3" audit-id:d3b77901-4536-46cf-a0b7-f734f8c39ff8,key:/monitoring.coreos.com/prometheuses/monitoring/stable-kube-prometheus-sta-prometheus,type:*unstructured.Unstructured,resource:prometheuses.monitoring.coreos.com 1037ms (09:46:45.212)
Trace[1552112191]:  ---"Txn call completed" 605ms (09:46:45.857)
Trace[1552112191]:  ---"decode succeeded" len:4976 384ms (09:46:46.241)]
Trace[1552112191]: ---"Object stored in database" 1014ms (09:46:46.242)
Trace[1552112191]: [1.038977309s] [1.038977309s] END
I0210 09:46:46.448531       1 trace.go:236] Trace[514837387]: "Delete" accept:application/json, */*,audit-id:1bd0b2d7-1501-47cb-af82-d8654e65ae95,client:10.244.0.18,protocol:HTTP/2.0,resource:secrets,scope:resource,url:/api/v1/namespaces/monitoring/secrets/alertmanager-stable-kube-prometheus-sta-alertmanager-tls-assets-1,user-agent:PrometheusOperator/0.71.2,verb:DELETE (10-Feb-2024 09:46:45.040) (total time: 1407ms):
Trace[514837387]: ---"limitedReadBody succeeded" len:43 1354ms (09:46:46.394)
Trace[514837387]: [1.407864479s] [1.407864479s] END
I0210 09:49:24.185253       1 handler.go:232] Adding GroupVersion monitoring.coreos.com v1alpha1 to ResourceManager
I0210 09:49:24.188105       1 handler.go:232] Adding GroupVersion monitoring.coreos.com v1 to ResourceManager
I0210 09:49:24.194327       1 handler.go:232] Adding GroupVersion monitoring.coreos.com v1 to ResourceManager
I0210 09:49:24.203383       1 handler.go:232] Adding GroupVersion monitoring.coreos.com v1alpha1 to ResourceManager
I0210 09:49:24.203563       1 handler.go:232] Adding GroupVersion monitoring.coreos.com v1 to ResourceManager
I0210 09:49:24.204347       1 handler.go:232] Adding GroupVersion monitoring.coreos.com v1alpha1 to ResourceManager
I0210 09:49:24.208874       1 handler.go:232] Adding GroupVersion monitoring.coreos.com v1 to ResourceManager
I0210 09:49:26.667958       1 trace.go:236] Trace[906492306]: "Delete" accept:application/json, */*,audit-id:a1d10da8-3811-47d7-a342-055d0414547d,client:10.244.0.18,protocol:HTTP/2.0,resource:secrets,scope:resource,url:/api/v1/namespaces/monitoring/secrets/prometheus-stable-kube-prometheus-sta-prometheus-tls-assets-1,user-agent:PrometheusOperator/0.71.2,verb:DELETE (10-Feb-2024 09:49:25.979) (total time: 686ms):
Trace[906492306]: [686.010784ms] [686.010784ms] END
I0210 09:49:26.667998       1 trace.go:236] Trace[1765060706]: "Get" accept:application/json, */*,audit-id:943fc8e0-a23b-400e-82ac-f8e091d50c8f,client:10.244.0.14,protocol:HTTP/2.0,resource:statefulsets,scope:resource,url:/apis/apps/v1/namespaces/monitoring/statefulsets/alertmanager-stable-kube-prometheus-sta-alertmanager,user-agent:PrometheusOperator/0.71.2,verb:GET (10-Feb-2024 09:49:26.026) (total time: 641ms):
Trace[1765060706]: ---"About to write a response" 640ms (09:49:26.666)
Trace[1765060706]: [641.027627ms] [641.027627ms] END
I0210 09:49:26.667959       1 trace.go:236] Trace[753793511]: "Update" accept:application/json, */*,audit-id:cfb1ca0a-605d-4902-be19-3ed0646a6a7e,client:10.244.0.18,protocol:HTTP/2.0,resource:statefulsets,scope:resource,url:/apis/apps/v1/namespaces/monitoring/statefulsets/alertmanager-stable-kube-prometheus-sta-alertmanager,user-agent:PrometheusOperator/0.71.2,verb:PUT (10-Feb-2024 09:49:25.961) (total time: 700ms):
Trace[753793511]: ["GuaranteedUpdate etcd3" audit-id:cfb1ca0a-605d-4902-be19-3ed0646a6a7e,key:/statefulsets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager,type:*apps.StatefulSet,resource:statefulsets.apps 701ms (09:49:25.963)
Trace[753793511]:  ---"Txn call completed" 686ms (09:49:26.661)]
Trace[753793511]: [700.687319ms] [700.687319ms] END
I0210 09:49:28.484816       1 trace.go:236] Trace[1180807166]: "Create" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:7c72a5fe-051b-44fa-84a0-9ed51aced1cc,client:192.168.49.2,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/monitoring/events,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:POST (10-Feb-2024 09:49:26.683) (total time: 1801ms):
Trace[1180807166]: ["Create etcd3" audit-id:7c72a5fe-051b-44fa-84a0-9ed51aced1cc,key:/events/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b277781bd1b5c6,type:*core.Event,resource:events 1800ms (09:49:26.684)
Trace[1180807166]:  ---"Txn call succeeded" 1800ms (09:49:28.484)]
Trace[1180807166]: [1.801538401s] [1.801538401s] END
I0210 09:49:28.487566       1 trace.go:236] Trace[499436560]: "Update" accept:application/json, */*,audit-id:b8645d2c-57d9-4bf3-a6e2-98bae6eba36f,client:10.244.0.18,protocol:HTTP/2.0,resource:secrets,scope:resource,url:/api/v1/namespaces/monitoring/secrets/prometheus-stable-kube-prometheus-sta-prometheus-web-config,user-agent:PrometheusOperator/0.71.2,verb:PUT (10-Feb-2024 09:49:26.680) (total time: 1806ms):
Trace[499436560]: ["GuaranteedUpdate etcd3" audit-id:b8645d2c-57d9-4bf3-a6e2-98bae6eba36f,key:/secrets/monitoring/prometheus-stable-kube-prometheus-sta-prometheus-web-config,type:*core.Secret,resource:secrets 1806ms (09:49:26.680)]
Trace[499436560]: [1.80687628s] [1.80687628s] END
I0210 09:49:28.490486       1 trace.go:236] Trace[1834418186]: "Get" accept:application/json, */*,audit-id:27326d9b-7c4d-446b-8a77-75ea21aa7c8a,client:10.244.0.18,protocol:HTTP/2.0,resource:secrets,scope:resource,url:/api/v1/namespaces/monitoring/secrets/alertmanager-stable-kube-prometheus-sta-alertmanager,user-agent:PrometheusOperator/0.71.2,verb:GET (10-Feb-2024 09:49:26.687) (total time: 1802ms):
Trace[1834418186]: ---"About to write a response" 1802ms (09:49:28.490)
Trace[1834418186]: [1.802468937s] [1.802468937s] END
I0210 09:49:28.499170       1 trace.go:236] Trace[1367592415]: "Get" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:7805e672-420b-42a0-863e-a74932bd2e72,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/monitoring/pods/prometheus-stable-kube-prometheus-sta-prometheus-0,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:GET (10-Feb-2024 09:49:27.857) (total time: 641ms):
Trace[1367592415]: ---"About to write a response" 633ms (09:49:28.491)
Trace[1367592415]: [641.948754ms] [641.948754ms] END
I0210 09:49:28.507405       1 trace.go:236] Trace[1957423493]: "Patch" accept:application/json, */*,audit-id:5ad800ad-3937-4a52-98aa-840d23faaead,client:10.244.0.18,protocol:HTTP/2.0,resource:alertmanagers,scope:resource,url:/apis/monitoring.coreos.com/v1/namespaces/monitoring/alertmanagers/stable-kube-prometheus-sta-alertmanager/status,user-agent:PrometheusOperator/0.71.2,verb:APPLY (10-Feb-2024 09:49:26.696) (total time: 1810ms):
Trace[1957423493]: ["GuaranteedUpdate etcd3" audit-id:5ad800ad-3937-4a52-98aa-840d23faaead,key:/monitoring.coreos.com/alertmanagers/monitoring/stable-kube-prometheus-sta-alertmanager,type:*unstructured.Unstructured,resource:alertmanagers.monitoring.coreos.com 1810ms (09:49:26.696)]
Trace[1957423493]: ---"Object stored in database" 1800ms (09:49:28.506)
Trace[1957423493]: [1.810164014s] [1.810164014s] END
I0210 09:49:28.510881       1 trace.go:236] Trace[696150501]: "Update" accept:application/json, */*,audit-id:1c92e83e-8e9f-49be-b09c-56abd5119f7a,client:10.244.0.14,protocol:HTTP/2.0,resource:statefulsets,scope:resource,url:/apis/apps/v1/namespaces/monitoring/statefulsets/alertmanager-stable-kube-prometheus-sta-alertmanager,user-agent:PrometheusOperator/0.71.2,verb:PUT (10-Feb-2024 09:49:26.829) (total time: 1681ms):
Trace[696150501]: ["GuaranteedUpdate etcd3" audit-id:1c92e83e-8e9f-49be-b09c-56abd5119f7a,key:/statefulsets/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager,type:*apps.StatefulSet,resource:statefulsets.apps 1679ms (09:49:26.831)
Trace[696150501]:  ---"Txn call completed" 1645ms (09:49:28.488)]
Trace[696150501]: ---"Writing http response done" 21ms (09:49:28.510)
Trace[696150501]: [1.681053501s] [1.681053501s] END
I0210 09:49:28.534027       1 trace.go:236] Trace[1478991299]: "List" accept:application/json, */*,audit-id:6aeaef7c-1a73-4774-9512-d6aba0a74e31,client:10.244.0.14,protocol:HTTP/2.0,resource:configmaps,scope:namespace,url:/api/v1/namespaces/monitoring/configmaps,user-agent:PrometheusOperator/0.71.2,verb:LIST (10-Feb-2024 09:49:27.334) (total time: 1199ms):
Trace[1478991299]: ["List(recursive=true) etcd3" audit-id:6aeaef7c-1a73-4774-9512-d6aba0a74e31,key:/configmaps/monitoring,resourceVersion:,resourceVersionMatch:,limit:0,continue: 1199ms (09:49:27.334)]
Trace[1478991299]: ---"Writing http response done" count:1 36ms (09:49:28.533)
Trace[1478991299]: [1.199672815s] [1.199672815s] END
I0210 09:50:07.979358       1 trace.go:236] Trace[1424577077]: "Delete" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:aaad74c6-a0e8-40f5-9795-409f4f34fff0,client:192.168.49.2,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/monitoring/pods/alertmanager-stable-kube-prometheus-sta-alertmanager-0,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:DELETE (10-Feb-2024 09:50:07.205) (total time: 773ms):
Trace[1424577077]: ["GuaranteedUpdate etcd3" audit-id:aaad74c6-a0e8-40f5-9795-409f4f34fff0,key:/pods/monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0,type:*core.Pod,resource:pods 765ms (09:50:07.213)
Trace[1424577077]:  ---"Txn call completed" 571ms (09:50:07.785)]
Trace[1424577077]: ---"Object deleted from database" 191ms (09:50:07.977)
Trace[1424577077]: [773.246663ms] [773.246663ms] END

* 
* ==> kube-controller-manager [12002bc09842] <==
* E0210 09:50:12.289704       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0210 09:50:12.301267       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0210 09:50:12.310271       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0210 09:50:12.322730       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0210 09:50:12.351485       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0210 09:50:12.363107       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0210 09:50:12.384737       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0210 09:50:12.396642       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0210 09:50:12.445868       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0210 09:50:12.468485       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0210 09:50:12.482218       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0210 09:50:12.486789       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0210 09:50:12.507389       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0210 09:50:12.655781       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0210 09:50:12.660526       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0210 09:50:12.686005       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0210 09:50:12.859180       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0210 09:50:12.872070       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0210 09:50:12.909374       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0210 09:50:12.952609       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0210 09:50:12.957240       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus failed error: pods \"prometheus-stable-kube-prometheus-sta-prometheus-0\" not found"
E0210 09:50:13.002681       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" not found
I0210 09:50:13.101666       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0210 09:50:15.014499       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager is recreating failed Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0"
I0210 09:50:15.278339       1 endpointslice_controller.go:310] "Error syncing endpoint slices for service, retrying" key="monitoring/stable-kube-prometheus-sta-alertmanager" err="EndpointSlice informer cache is out of date"
I0210 09:50:15.354206       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
I0210 09:50:15.394407       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
I0210 09:50:16.046955       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
I0210 09:50:16.990395       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0210 09:50:20.303431       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0210 09:50:20.396726       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0210 09:50:20.588311       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0210 09:50:20.671206       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0210 09:50:20.683638       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0210 09:50:20.887601       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0210 09:50:20.898540       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0210 09:50:20.997339       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0210 09:50:21.185083       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0210 09:50:22.086023       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager is recreating failed Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0"
E0210 09:50:22.253640       1 stateful_set.go:430] error syncing StatefulSet monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager, requeuing: pods "alertmanager-stable-kube-prometheus-sta-alertmanager-0" not found
I0210 09:50:22.254058       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedDelete" message="delete Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager failed error: pods \"alertmanager-stable-kube-prometheus-sta-alertmanager-0\" not found"
I0210 09:50:22.358543       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
I0210 09:50:22.693766       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
I0210 09:50:23.867514       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0210 09:50:26.683238       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager is recreating failed Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0"
I0210 09:50:26.690898       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
E0210 09:50:26.789999       1 stateful_set.go:430] error syncing StatefulSet monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager, requeuing: object is being deleted: pods "alertmanager-stable-kube-prometheus-sta-alertmanager-0" already exists, the server was not able to generate a unique name for the object
I0210 09:50:26.885469       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
I0210 09:50:26.898953       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0210 09:50:26.978020       1 endpointslice_controller.go:310] "Error syncing endpoint slices for service, retrying" key="monitoring/prometheus-operated" err="EndpointSlice informer cache is out of date"
I0210 09:50:26.994613       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0210 09:50:27.070684       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0210 09:50:27.810820       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
I0210 09:50:31.200711       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0210 09:50:31.665815       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager is recreating failed Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0"
E0210 09:50:31.705005       1 stateful_set.go:430] error syncing StatefulSet monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager, requeuing: pods "alertmanager-stable-kube-prometheus-sta-alertmanager-0" not found
I0210 09:50:31.706025       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedDelete" message="delete Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager failed error: pods \"alertmanager-stable-kube-prometheus-sta-alertmanager-0\" not found"
I0210 09:50:31.708133       1 endpointslice_controller.go:310] "Error syncing endpoint slices for service, retrying" key="monitoring/alertmanager-operated" err="EndpointSlice informer cache is out of date"
I0210 09:50:31.778355       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
I0210 09:50:32.473700       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"

* 
* ==> kube-controller-manager [ed40fc1b38b6] <==
* I0212 02:59:29.515275       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0212 02:59:29.873343       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0212 02:59:29.888755       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 02:59:29.908223       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0212 02:59:29.925468       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0212 02:59:29.971744       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 02:59:29.975565       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0212 02:59:30.005915       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0212 02:59:30.021325       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 02:59:30.063027       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0212 02:59:30.079199       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0212 02:59:30.087283       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 02:59:30.096163       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0212 02:59:30.115678       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0212 02:59:30.127034       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 02:59:30.134347       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0212 02:59:30.179450       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0212 02:59:30.396841       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 02:59:30.404544       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0212 02:59:30.511230       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0212 02:59:30.574896       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 02:59:30.587725       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0212 02:59:30.668939       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: object is being deleted: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" already exists, the server was not able to generate a unique name for the object
I0212 02:59:30.696614       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 02:59:30.706833       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus failed error: pods \"prometheus-stable-kube-prometheus-sta-prometheus-0\" not found"
E0212 02:59:30.770491       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" not found
I0212 02:59:30.807355       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 02:59:33.394830       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 02:59:37.962555       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 02:59:38.008065       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 02:59:38.174186       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 02:59:41.078795       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 02:59:45.183899       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 02:59:45.224557       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 02:59:45.305335       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 02:59:46.762494       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager is recreating failed Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0"
I0212 02:59:46.882248       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
E0212 02:59:47.413540       1 stateful_set.go:430] error syncing StatefulSet monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager, requeuing: object is being deleted: pods "alertmanager-stable-kube-prometheus-sta-alertmanager-0" already exists, the server was not able to generate a unique name for the object
I0212 02:59:47.593691       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
I0212 02:59:48.189322       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
I0212 02:59:48.677717       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 02:59:53.396937       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 02:59:53.476281       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 02:59:53.608672       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 02:59:53.989990       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
I0212 02:59:55.307285       1 event.go:307] "Event occurred" object="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 in StatefulSet alertmanager-stable-kube-prometheus-sta-alertmanager successful"
I0212 02:59:56.938300       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 03:00:03.377950       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 03:00:03.408156       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="FailedDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus failed error: pods \"prometheus-stable-kube-prometheus-sta-prometheus-0\" not found"
E0212 03:00:03.408710       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: pods "prometheus-stable-kube-prometheus-sta-prometheus-0" not found
I0212 03:00:03.582696       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 03:00:04.501759       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 03:00:16.919220       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 03:00:17.004428       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 03:00:17.161235       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 03:00:18.577897       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
E0212 03:00:18.905791       1 stateful_set.go:430] error syncing StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus, requeuing: StatefulSet.apps "prometheus-stable-kube-prometheus-sta-prometheus" is invalid: status.currentReplicas: Invalid value: -1: must be greater than or equal to 0
I0212 03:00:32.685565       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Warning" reason="RecreatingFailedPod" message="StatefulSet monitoring/prometheus-stable-kube-prometheus-sta-prometheus is recreating failed Pod prometheus-stable-kube-prometheus-sta-prometheus-0"
I0212 03:00:32.722444       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="delete Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"
I0212 03:00:32.876351       1 event.go:307] "Event occurred" object="monitoring/prometheus-stable-kube-prometheus-sta-prometheus" fieldPath="" kind="StatefulSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="create Pod prometheus-stable-kube-prometheus-sta-prometheus-0 in StatefulSet prometheus-stable-kube-prometheus-sta-prometheus successful"

* 
* ==> kube-proxy [0bfe65d17ea8] <==
* I0212 02:15:46.136343       1 server_others.go:69] "Using iptables proxy"
I0212 02:15:46.421636       1 node.go:141] Successfully retrieved node IP: 192.168.49.2
I0212 02:15:48.074757       1 server.go:632] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0212 02:15:48.236460       1 server_others.go:152] "Using iptables Proxier"
I0212 02:15:48.237232       1 server_others.go:421] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR for family" ipFamily="IPv6"
I0212 02:15:48.237952       1 server_others.go:438] "Defaulting to no-op detect-local"
I0212 02:15:48.275401       1 proxier.go:251] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0212 02:15:48.276447       1 server.go:846] "Version info" version="v1.28.3"
I0212 02:15:48.277126       1 server.go:848] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0212 02:15:48.297527       1 config.go:97] "Starting endpoint slice config controller"
I0212 02:15:48.303031       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0212 02:15:48.303156       1 config.go:188] "Starting service config controller"
I0212 02:15:48.303170       1 shared_informer.go:311] Waiting for caches to sync for service config
I0212 02:15:48.304941       1 config.go:315] "Starting node config controller"
I0212 02:15:48.305024       1 shared_informer.go:311] Waiting for caches to sync for node config
I0212 02:15:48.691562       1 shared_informer.go:318] Caches are synced for node config
I0212 02:15:48.805270       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0212 02:15:48.805431       1 shared_informer.go:318] Caches are synced for service config
I0212 02:24:51.489488       1 trace.go:236] Trace[1627526847]: "iptables ChainExists" (12-Feb-2024 02:24:48.418) (total time: 2313ms):
Trace[1627526847]: [2.313188386s] [2.313188386s] END
I0212 02:24:53.727194       1 trace.go:236] Trace[31063272]: "iptables restore" (12-Feb-2024 02:24:51.485) (total time: 2372ms):
Trace[31063272]: [2.37298756s] [2.37298756s] END

* 
* ==> kube-proxy [ce6681fe1920] <==
* I0210 01:05:14.102606       1 server_others.go:69] "Using iptables proxy"
I0210 01:05:14.514993       1 node.go:141] Successfully retrieved node IP: 192.168.49.2
I0210 01:05:15.431170       1 server.go:632] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0210 01:05:15.444985       1 server_others.go:152] "Using iptables Proxier"
I0210 01:05:15.445317       1 server_others.go:421] "Detect-local-mode set to ClusterCIDR, but no cluster CIDR for family" ipFamily="IPv6"
I0210 01:05:15.445449       1 server_others.go:438] "Defaulting to no-op detect-local"
I0210 01:05:15.446220       1 proxier.go:251] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0210 01:05:15.452074       1 server.go:846] "Version info" version="v1.28.3"
I0210 01:05:15.452187       1 server.go:848] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0210 01:05:15.540261       1 config.go:97] "Starting endpoint slice config controller"
I0210 01:05:15.542036       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0210 01:05:15.543339       1 config.go:188] "Starting service config controller"
I0210 01:05:15.543384       1 shared_informer.go:311] Waiting for caches to sync for service config
I0210 01:05:15.544449       1 config.go:315] "Starting node config controller"
I0210 01:05:15.544531       1 shared_informer.go:311] Waiting for caches to sync for node config
I0210 01:05:15.852574       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0210 01:05:15.854100       1 shared_informer.go:318] Caches are synced for service config
I0210 01:05:16.158509       1 shared_informer.go:318] Caches are synced for node config
I0210 06:02:43.358495       1 trace.go:236] Trace[415068220]: "iptables ChainExists" (10-Feb-2024 06:02:41.559) (total time: 2008ms):
Trace[415068220]: [2.008741241s] [2.008741241s] END
I0210 07:41:07.707330       1 trace.go:236] Trace[1791896518]: "iptables ChainExists" (10-Feb-2024 07:41:04.323) (total time: 3089ms):
Trace[1791896518]: [3.089971673s] [3.089971673s] END
I0210 09:44:24.673726       1 trace.go:236] Trace[1649258390]: "DeltaFIFO Pop Process" ID:default/prometheus-operator,Depth:17,Reason:slow event handlers blocking the queue (10-Feb-2024 09:44:23.944) (total time: 228ms):
Trace[1649258390]: [228.777264ms] [228.777264ms] END
I0210 09:44:26.466306       1 trace.go:236] Trace[1932534139]: "iptables save" (10-Feb-2024 09:44:21.710) (total time: 4755ms):
Trace[1932534139]: [4.7557454s] [4.7557454s] END

* 
* ==> kube-scheduler [76466e307e84] <==
* I0212 02:15:27.992265       1 serving.go:348] Generated self-signed cert in-memory
W0212 02:15:37.599641       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0212 02:15:37.599901       1 authentication.go:368] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0212 02:15:37.599925       1 authentication.go:369] Continuing without authentication configuration. This may treat all requests as anonymous.
W0212 02:15:37.599991       1 authentication.go:370] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0212 02:15:37.815208       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.28.3"
I0212 02:15:37.815275       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0212 02:15:37.827331       1 secure_serving.go:213] Serving securely on 127.0.0.1:10259
I0212 02:15:37.836851       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0212 02:15:37.838923       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0212 02:15:37.839070       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0212 02:15:38.077859       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0212 02:22:21.101539       1 trace.go:236] Trace[2002991660]: "Scheduling" namespace:monitoring,name:prometheus-stable-kube-prometheus-sta-prometheus-0 (12-Feb-2024 02:22:20.737) (total time: 137ms):
Trace[2002991660]: ---"Computing predicates done" 135ms (02:22:20.874)
Trace[2002991660]: [137.230754ms] [137.230754ms] END
I0212 02:48:26.299842       1 trace.go:236] Trace[58487100]: "Scheduling" namespace:monitoring,name:alertmanager-stable-kube-prometheus-sta-alertmanager-0 (12-Feb-2024 02:48:26.113) (total time: 118ms):
Trace[58487100]: ---"Computing predicates done" 113ms (02:48:26.231)
Trace[58487100]: [118.102045ms] [118.102045ms] END
E0212 02:49:49.500058       1 framework.go:1206] "Plugin Failed" err="Operation cannot be fulfilled on pods/binding \"alertmanager-stable-kube-prometheus-sta-alertmanager-0\": pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 is being deleted, cannot be assigned to a host" plugin="DefaultBinder" pod="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0" node="minikube"
E0212 02:49:49.518911       1 schedule_one.go:989] "Error scheduling pod; retrying" err="running Bind plugin \"DefaultBinder\": Operation cannot be fulfilled on pods/binding \"alertmanager-stable-kube-prometheus-sta-alertmanager-0\": pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 is being deleted, cannot be assigned to a host" pod="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0"
I0212 02:49:49.591411       1 schedule_one.go:996] "Pod doesn't exist in informer cache" pod="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0" err="pod \"alertmanager-stable-kube-prometheus-sta-alertmanager-0\" not found"
E0212 02:49:50.176155       1 schedule_one.go:1038] "Error updating pod" err="pods \"alertmanager-stable-kube-prometheus-sta-alertmanager-0\" not found" pod="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0"
E0212 02:51:49.871523       1 framework.go:1206] "Plugin Failed" err="Operation cannot be fulfilled on pods/binding \"alertmanager-stable-kube-prometheus-sta-alertmanager-0\": pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 is being deleted, cannot be assigned to a host" plugin="DefaultBinder" pod="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0" node="minikube"
E0212 02:51:49.880566       1 schedule_one.go:989] "Error scheduling pod; retrying" err="running Bind plugin \"DefaultBinder\": Operation cannot be fulfilled on pods/binding \"alertmanager-stable-kube-prometheus-sta-alertmanager-0\": pod alertmanager-stable-kube-prometheus-sta-alertmanager-0 is being deleted, cannot be assigned to a host" pod="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0"
I0212 02:51:49.890759       1 schedule_one.go:996] "Pod doesn't exist in informer cache" pod="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0" err="pod \"alertmanager-stable-kube-prometheus-sta-alertmanager-0\" not found"
E0212 02:51:50.115558       1 schedule_one.go:1038] "Error updating pod" err="pods \"alertmanager-stable-kube-prometheus-sta-alertmanager-0\" not found" pod="monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0"
I0212 02:54:38.276574       1 trace.go:236] Trace[1424979148]: "Scheduling" namespace:monitoring,name:prometheus-stable-kube-prometheus-sta-prometheus-0 (12-Feb-2024 02:54:38.114) (total time: 104ms):
Trace[1424979148]: ---"Snapshotting scheduler cache and node infos done" 52ms (02:54:38.166)
Trace[1424979148]: ---"Computing predicates done" 52ms (02:54:38.219)
Trace[1424979148]: [104.878089ms] [104.878089ms] END
I0212 02:55:07.203292       1 trace.go:236] Trace[1654813313]: "Scheduling" namespace:monitoring,name:prometheus-stable-kube-prometheus-sta-prometheus-0 (12-Feb-2024 02:55:07.014) (total time: 111ms):
Trace[1654813313]: ---"Snapshotting scheduler cache and node infos done" 59ms (02:55:07.074)
Trace[1654813313]: ---"Computing predicates done" 51ms (02:55:07.126)
Trace[1654813313]: [111.904393ms] [111.904393ms] END

* 
* ==> kube-scheduler [b0c18930c6c8] <==
* I0210 01:05:01.514776       1 serving.go:348] Generated self-signed cert in-memory
W0210 01:05:05.626177       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0210 01:05:05.626273       1 authentication.go:368] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0210 01:05:05.626297       1 authentication.go:369] Continuing without authentication configuration. This may treat all requests as anonymous.
W0210 01:05:05.626310       1 authentication.go:370] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0210 01:05:05.764224       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.28.3"
I0210 01:05:05.764282       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0210 01:05:05.770795       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0210 01:05:05.770903       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0210 01:05:05.797183       1 secure_serving.go:213] Serving securely on 127.0.0.1:10259
I0210 01:05:05.797513       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0210 01:05:05.872290       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
E0210 08:35:41.146660       1 event_broadcaster.go:265] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"alertmanager-stable-kube-prometheus-sta-alertmanager-0.17b273047a50d653", GenerateName:"", Namespace:"monitoring", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, EventTime:time.Date(2024, time.February, 10, 8, 27, 51, 796010775, time.Local), Series:(*v1.EventSeries)(nil), ReportingController:"default-scheduler", ReportingInstance:"default-scheduler-minikube", Action:"Binding", Reason:"Scheduled", Regarding:v1.ObjectReference{Kind:"Pod", Namespace:"monitoring", Name:"alertmanager-stable-kube-prometheus-sta-alertmanager-0", UID:"affa5743-8d2c-469d-b668-3000e4d7cb51", APIVersion:"v1", ResourceVersion:"38039", FieldPath:""}, Related:(*v1.ObjectReference)(nil), Note:"Successfully assigned monitoring/alertmanager-stable-kube-prometheus-sta-alertmanager-0 to minikube", Type:"Normal", DeprecatedSource:v1.EventSource{Component:"", Host:""}, DeprecatedFirstTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeprecatedLastTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeprecatedCount:0}': 'the server was unable to return a response in the time allotted, but may still be processing the request (post events.events.k8s.io)' (will not retry!)

* 
* ==> kubelet <==
* Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.061640    1430 operation_generator.go:882] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/e9b01342-0de8-4a4e-89ac-f4860daebcfe-tls-assets" (OuterVolumeSpecName: "tls-assets") pod "e9b01342-0de8-4a4e-89ac-f4860daebcfe" (UID: "e9b01342-0de8-4a4e-89ac-f4860daebcfe"). InnerVolumeSpecName "tls-assets". PluginName "kubernetes.io/projected", VolumeGidValue ""
Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.065661    1430 operation_generator.go:882] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/e9b01342-0de8-4a4e-89ac-f4860daebcfe-kube-api-access-586fb" (OuterVolumeSpecName: "kube-api-access-586fb") pod "e9b01342-0de8-4a4e-89ac-f4860daebcfe" (UID: "e9b01342-0de8-4a4e-89ac-f4860daebcfe"). InnerVolumeSpecName "kube-api-access-586fb". PluginName "kubernetes.io/projected", VolumeGidValue ""
Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.066362    1430 operation_generator.go:882] UnmountVolume.TearDown succeeded for volume "kubernetes.io/empty-dir/e9b01342-0de8-4a4e-89ac-f4860daebcfe-config-out" (OuterVolumeSpecName: "config-out") pod "e9b01342-0de8-4a4e-89ac-f4860daebcfe" (UID: "e9b01342-0de8-4a4e-89ac-f4860daebcfe"). InnerVolumeSpecName "config-out". PluginName "kubernetes.io/empty-dir", VolumeGidValue ""
Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.066935    1430 operation_generator.go:882] UnmountVolume.TearDown succeeded for volume "kubernetes.io/secret/e9b01342-0de8-4a4e-89ac-f4860daebcfe-config" (OuterVolumeSpecName: "config") pod "e9b01342-0de8-4a4e-89ac-f4860daebcfe" (UID: "e9b01342-0de8-4a4e-89ac-f4860daebcfe"). InnerVolumeSpecName "config". PluginName "kubernetes.io/secret", VolumeGidValue ""
Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.073343    1430 operation_generator.go:882] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/e9b01342-0de8-4a4e-89ac-f4860daebcfe-prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0" (OuterVolumeSpecName: "prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0") pod "e9b01342-0de8-4a4e-89ac-f4860daebcfe" (UID: "e9b01342-0de8-4a4e-89ac-f4860daebcfe"). InnerVolumeSpecName "prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.108426    1430 reconciler_common.go:300] "Volume detached for volume \"config\" (UniqueName: \"kubernetes.io/secret/e9b01342-0de8-4a4e-89ac-f4860daebcfe-config\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.108507    1430 reconciler_common.go:300] "Volume detached for volume \"prometheus-stable-kube-prometheus-sta-prometheus-db\" (UniqueName: \"kubernetes.io/empty-dir/e9b01342-0de8-4a4e-89ac-f4860daebcfe-prometheus-stable-kube-prometheus-sta-prometheus-db\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.108606    1430 reconciler_common.go:300] "Volume detached for volume \"prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0\" (UniqueName: \"kubernetes.io/configmap/e9b01342-0de8-4a4e-89ac-f4860daebcfe-prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.108638    1430 reconciler_common.go:300] "Volume detached for volume \"tls-assets\" (UniqueName: \"kubernetes.io/projected/e9b01342-0de8-4a4e-89ac-f4860daebcfe-tls-assets\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.108663    1430 reconciler_common.go:300] "Volume detached for volume \"web-config\" (UniqueName: \"kubernetes.io/secret/e9b01342-0de8-4a4e-89ac-f4860daebcfe-web-config\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.108687    1430 reconciler_common.go:300] "Volume detached for volume \"kube-api-access-586fb\" (UniqueName: \"kubernetes.io/projected/e9b01342-0de8-4a4e-89ac-f4860daebcfe-kube-api-access-586fb\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.109647    1430 reconciler_common.go:300] "Volume detached for volume \"config-out\" (UniqueName: \"kubernetes.io/empty-dir/e9b01342-0de8-4a4e-89ac-f4860daebcfe-config-out\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:16 minikube kubelet[1430]: I0212 03:00:16.724279    1430 scope.go:117] "RemoveContainer" containerID="c286a4d9885265a2e602abbd68aebc5fb538560bfb3a5b4f30bd2eed5e19128e"
Feb 12 03:00:17 minikube kubelet[1430]: I0212 03:00:17.313256    1430 topology_manager.go:215] "Topology Admit Handler" podUID="41ba165c-994d-44e8-b79e-2b7de0d11d8d" podNamespace="monitoring" podName="prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:17 minikube kubelet[1430]: E0212 03:00:17.324725    1430 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="e9b01342-0de8-4a4e-89ac-f4860daebcfe" containerName="init-config-reloader"
Feb 12 03:00:17 minikube kubelet[1430]: I0212 03:00:17.365053    1430 memory_manager.go:346] "RemoveStaleState removing state" podUID="e9b01342-0de8-4a4e-89ac-f4860daebcfe" containerName="init-config-reloader"
Feb 12 03:00:17 minikube kubelet[1430]: I0212 03:00:17.496022    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"web-config\" (UniqueName: \"kubernetes.io/secret/41ba165c-994d-44e8-b79e-2b7de0d11d8d-web-config\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:17 minikube kubelet[1430]: I0212 03:00:17.496189    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config\" (UniqueName: \"kubernetes.io/secret/41ba165c-994d-44e8-b79e-2b7de0d11d8d-config\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:17 minikube kubelet[1430]: I0212 03:00:17.496225    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tls-assets\" (UniqueName: \"kubernetes.io/projected/41ba165c-994d-44e8-b79e-2b7de0d11d8d-tls-assets\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:17 minikube kubelet[1430]: I0212 03:00:17.496261    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"prometheus-stable-kube-prometheus-sta-prometheus-db\" (UniqueName: \"kubernetes.io/empty-dir/41ba165c-994d-44e8-b79e-2b7de0d11d8d-prometheus-stable-kube-prometheus-sta-prometheus-db\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:17 minikube kubelet[1430]: I0212 03:00:17.496303    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0\" (UniqueName: \"kubernetes.io/configmap/41ba165c-994d-44e8-b79e-2b7de0d11d8d-prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:17 minikube kubelet[1430]: I0212 03:00:17.496348    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-out\" (UniqueName: \"kubernetes.io/empty-dir/41ba165c-994d-44e8-b79e-2b7de0d11d8d-config-out\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:17 minikube kubelet[1430]: I0212 03:00:17.496380    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-8qc88\" (UniqueName: \"kubernetes.io/projected/41ba165c-994d-44e8-b79e-2b7de0d11d8d-kube-api-access-8qc88\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:19 minikube kubelet[1430]: I0212 03:00:19.266906    1430 kubelet_volumes.go:161] "Cleaned up orphaned pod volumes dir" podUID="e9b01342-0de8-4a4e-89ac-f4860daebcfe" path="/var/lib/kubelet/pods/e9b01342-0de8-4a4e-89ac-f4860daebcfe/volumes"
Feb 12 03:00:21 minikube kubelet[1430]: W0212 03:00:21.163606    1430 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Feb 12 03:00:22 minikube kubelet[1430]: I0212 03:00:22.726106    1430 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="951e08671dd4dc8e5ab3af13e7fbd34ed882fa8dc415dc8a84b004547aad8e36"
Feb 12 03:00:30 minikube kubelet[1430]: I0212 03:00:30.960723    1430 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"tls-assets\" (UniqueName: \"kubernetes.io/projected/41ba165c-994d-44e8-b79e-2b7de0d11d8d-tls-assets\") pod \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") "
Feb 12 03:00:30 minikube kubelet[1430]: I0212 03:00:30.962683    1430 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"prometheus-stable-kube-prometheus-sta-prometheus-db\" (UniqueName: \"kubernetes.io/empty-dir/41ba165c-994d-44e8-b79e-2b7de0d11d8d-prometheus-stable-kube-prometheus-sta-prometheus-db\") pod \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") "
Feb 12 03:00:30 minikube kubelet[1430]: I0212 03:00:30.962912    1430 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"config-out\" (UniqueName: \"kubernetes.io/empty-dir/41ba165c-994d-44e8-b79e-2b7de0d11d8d-config-out\") pod \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") "
Feb 12 03:00:30 minikube kubelet[1430]: I0212 03:00:30.962992    1430 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"config\" (UniqueName: \"kubernetes.io/secret/41ba165c-994d-44e8-b79e-2b7de0d11d8d-config\") pod \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") "
Feb 12 03:00:30 minikube kubelet[1430]: I0212 03:00:30.964813    1430 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0\" (UniqueName: \"kubernetes.io/configmap/41ba165c-994d-44e8-b79e-2b7de0d11d8d-prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0\") pod \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") "
Feb 12 03:00:30 minikube kubelet[1430]: I0212 03:00:30.964895    1430 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"web-config\" (UniqueName: \"kubernetes.io/secret/41ba165c-994d-44e8-b79e-2b7de0d11d8d-web-config\") pod \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") "
Feb 12 03:00:30 minikube kubelet[1430]: I0212 03:00:30.964951    1430 reconciler_common.go:172] "operationExecutor.UnmountVolume started for volume \"kube-api-access-8qc88\" (UniqueName: \"kubernetes.io/projected/41ba165c-994d-44e8-b79e-2b7de0d11d8d-kube-api-access-8qc88\") pod \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\" (UID: \"41ba165c-994d-44e8-b79e-2b7de0d11d8d\") "
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.065400    1430 operation_generator.go:882] UnmountVolume.TearDown succeeded for volume "kubernetes.io/empty-dir/41ba165c-994d-44e8-b79e-2b7de0d11d8d-prometheus-stable-kube-prometheus-sta-prometheus-db" (OuterVolumeSpecName: "prometheus-stable-kube-prometheus-sta-prometheus-db") pod "41ba165c-994d-44e8-b79e-2b7de0d11d8d" (UID: "41ba165c-994d-44e8-b79e-2b7de0d11d8d"). InnerVolumeSpecName "prometheus-stable-kube-prometheus-sta-prometheus-db". PluginName "kubernetes.io/empty-dir", VolumeGidValue ""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.071053    1430 reconciler_common.go:300] "Volume detached for volume \"prometheus-stable-kube-prometheus-sta-prometheus-db\" (UniqueName: \"kubernetes.io/empty-dir/41ba165c-994d-44e8-b79e-2b7de0d11d8d-prometheus-stable-kube-prometheus-sta-prometheus-db\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.083551    1430 operation_generator.go:882] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/41ba165c-994d-44e8-b79e-2b7de0d11d8d-prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0" (OuterVolumeSpecName: "prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0") pod "41ba165c-994d-44e8-b79e-2b7de0d11d8d" (UID: "41ba165c-994d-44e8-b79e-2b7de0d11d8d"). InnerVolumeSpecName "prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.094732    1430 operation_generator.go:882] UnmountVolume.TearDown succeeded for volume "kubernetes.io/secret/41ba165c-994d-44e8-b79e-2b7de0d11d8d-web-config" (OuterVolumeSpecName: "web-config") pod "41ba165c-994d-44e8-b79e-2b7de0d11d8d" (UID: "41ba165c-994d-44e8-b79e-2b7de0d11d8d"). InnerVolumeSpecName "web-config". PluginName "kubernetes.io/secret", VolumeGidValue ""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.095356    1430 operation_generator.go:882] UnmountVolume.TearDown succeeded for volume "kubernetes.io/empty-dir/41ba165c-994d-44e8-b79e-2b7de0d11d8d-config-out" (OuterVolumeSpecName: "config-out") pod "41ba165c-994d-44e8-b79e-2b7de0d11d8d" (UID: "41ba165c-994d-44e8-b79e-2b7de0d11d8d"). InnerVolumeSpecName "config-out". PluginName "kubernetes.io/empty-dir", VolumeGidValue ""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.099196    1430 operation_generator.go:882] UnmountVolume.TearDown succeeded for volume "kubernetes.io/secret/41ba165c-994d-44e8-b79e-2b7de0d11d8d-config" (OuterVolumeSpecName: "config") pod "41ba165c-994d-44e8-b79e-2b7de0d11d8d" (UID: "41ba165c-994d-44e8-b79e-2b7de0d11d8d"). InnerVolumeSpecName "config". PluginName "kubernetes.io/secret", VolumeGidValue ""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.101717    1430 operation_generator.go:882] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/41ba165c-994d-44e8-b79e-2b7de0d11d8d-kube-api-access-8qc88" (OuterVolumeSpecName: "kube-api-access-8qc88") pod "41ba165c-994d-44e8-b79e-2b7de0d11d8d" (UID: "41ba165c-994d-44e8-b79e-2b7de0d11d8d"). InnerVolumeSpecName "kube-api-access-8qc88". PluginName "kubernetes.io/projected", VolumeGidValue ""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.105884    1430 operation_generator.go:882] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/41ba165c-994d-44e8-b79e-2b7de0d11d8d-tls-assets" (OuterVolumeSpecName: "tls-assets") pod "41ba165c-994d-44e8-b79e-2b7de0d11d8d" (UID: "41ba165c-994d-44e8-b79e-2b7de0d11d8d"). InnerVolumeSpecName "tls-assets". PluginName "kubernetes.io/projected", VolumeGidValue ""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.171441    1430 reconciler_common.go:300] "Volume detached for volume \"web-config\" (UniqueName: \"kubernetes.io/secret/41ba165c-994d-44e8-b79e-2b7de0d11d8d-web-config\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.171512    1430 reconciler_common.go:300] "Volume detached for volume \"kube-api-access-8qc88\" (UniqueName: \"kubernetes.io/projected/41ba165c-994d-44e8-b79e-2b7de0d11d8d-kube-api-access-8qc88\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.171543    1430 reconciler_common.go:300] "Volume detached for volume \"tls-assets\" (UniqueName: \"kubernetes.io/projected/41ba165c-994d-44e8-b79e-2b7de0d11d8d-tls-assets\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.171568    1430 reconciler_common.go:300] "Volume detached for volume \"config-out\" (UniqueName: \"kubernetes.io/empty-dir/41ba165c-994d-44e8-b79e-2b7de0d11d8d-config-out\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.171590    1430 reconciler_common.go:300] "Volume detached for volume \"config\" (UniqueName: \"kubernetes.io/secret/41ba165c-994d-44e8-b79e-2b7de0d11d8d-config\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:31 minikube kubelet[1430]: I0212 03:00:31.171617    1430 reconciler_common.go:300] "Volume detached for volume \"prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0\" (UniqueName: \"kubernetes.io/configmap/41ba165c-994d-44e8-b79e-2b7de0d11d8d-prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0\") on node \"minikube\" DevicePath \"\""
Feb 12 03:00:32 minikube kubelet[1430]: I0212 03:00:32.014085    1430 scope.go:117] "RemoveContainer" containerID="b0df6b81183583785aa508701b4b13d1241279a40ee75c1e0530df3c622217b5"
Feb 12 03:00:33 minikube kubelet[1430]: I0212 03:00:33.217067    1430 kubelet_volumes.go:161] "Cleaned up orphaned pod volumes dir" podUID="41ba165c-994d-44e8-b79e-2b7de0d11d8d" path="/var/lib/kubelet/pods/41ba165c-994d-44e8-b79e-2b7de0d11d8d/volumes"
Feb 12 03:00:33 minikube kubelet[1430]: I0212 03:00:33.332823    1430 topology_manager.go:215] "Topology Admit Handler" podUID="97134f3a-56ed-4108-ba14-322921094a39" podNamespace="monitoring" podName="prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:33 minikube kubelet[1430]: E0212 03:00:33.338952    1430 cpu_manager.go:395] "RemoveStaleState: removing container" podUID="41ba165c-994d-44e8-b79e-2b7de0d11d8d" containerName="init-config-reloader"
Feb 12 03:00:33 minikube kubelet[1430]: I0212 03:00:33.363980    1430 memory_manager.go:346] "RemoveStaleState removing state" podUID="41ba165c-994d-44e8-b79e-2b7de0d11d8d" containerName="init-config-reloader"
Feb 12 03:00:33 minikube kubelet[1430]: I0212 03:00:33.567857    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-out\" (UniqueName: \"kubernetes.io/empty-dir/97134f3a-56ed-4108-ba14-322921094a39-config-out\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"97134f3a-56ed-4108-ba14-322921094a39\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:33 minikube kubelet[1430]: I0212 03:00:33.568024    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tls-assets\" (UniqueName: \"kubernetes.io/projected/97134f3a-56ed-4108-ba14-322921094a39-tls-assets\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"97134f3a-56ed-4108-ba14-322921094a39\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:33 minikube kubelet[1430]: I0212 03:00:33.568146    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0\" (UniqueName: \"kubernetes.io/configmap/97134f3a-56ed-4108-ba14-322921094a39-prometheus-stable-kube-prometheus-sta-prometheus-rulefiles-0\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"97134f3a-56ed-4108-ba14-322921094a39\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:33 minikube kubelet[1430]: I0212 03:00:33.568251    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"web-config\" (UniqueName: \"kubernetes.io/secret/97134f3a-56ed-4108-ba14-322921094a39-web-config\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"97134f3a-56ed-4108-ba14-322921094a39\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:33 minikube kubelet[1430]: I0212 03:00:33.568315    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-lw579\" (UniqueName: \"kubernetes.io/projected/97134f3a-56ed-4108-ba14-322921094a39-kube-api-access-lw579\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"97134f3a-56ed-4108-ba14-322921094a39\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:33 minikube kubelet[1430]: I0212 03:00:33.568375    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"prometheus-stable-kube-prometheus-sta-prometheus-db\" (UniqueName: \"kubernetes.io/empty-dir/97134f3a-56ed-4108-ba14-322921094a39-prometheus-stable-kube-prometheus-sta-prometheus-db\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"97134f3a-56ed-4108-ba14-322921094a39\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:33 minikube kubelet[1430]: I0212 03:00:33.568455    1430 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config\" (UniqueName: \"kubernetes.io/secret/97134f3a-56ed-4108-ba14-322921094a39-config\") pod \"prometheus-stable-kube-prometheus-sta-prometheus-0\" (UID: \"97134f3a-56ed-4108-ba14-322921094a39\") " pod="monitoring/prometheus-stable-kube-prometheus-sta-prometheus-0"
Feb 12 03:00:37 minikube kubelet[1430]: I0212 03:00:37.689303    1430 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="07500aa239a239eb1de0daa35aadea89fc1fc709fd89a8b69e707e9dae5248c7"

* 
* ==> storage-provisioner [180fc8eca507] <==
* I0212 02:16:05.485141       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0212 02:16:05.698501       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0212 02:16:05.704677       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0212 02:16:23.582106       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0212 02:16:23.582439       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_15e3187c-03f5-4e53-bf06-c28b1500ba1e!
I0212 02:16:23.588155       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"baf29698-f2c3-46e6-9770-70350ddb6000", APIVersion:"v1", ResourceVersion:"59186", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_15e3187c-03f5-4e53-bf06-c28b1500ba1e became leader
I0212 02:16:23.835215       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_15e3187c-03f5-4e53-bf06-c28b1500ba1e!

* 
* ==> storage-provisioner [b4f31634bd88] <==
* I0212 02:15:45.905605       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0212 02:15:46.039518       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": x509: certificate signed by unknown authority

